/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
wandb: Currently logged in as: vaibhav-agrawal (vaibhav-agrawal-19). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/rishubhp/.netrc
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/rishubhp/vaibhav/meesho-project/training_scripts/wandb/run-20240821_115913-zjl62s93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run poseonly_nosubjectinprompt
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vaibhav-agrawal-19/iisc
wandb: üöÄ View run at https://wandb.ai/vaibhav-agrawal-19/iisc/runs/zjl62s93
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
  0%|          | 0/200000 [00:00<?, ?it/s]<=============================== step 0  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9690], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 0/200000 [00:02<?, ?it/s]stage 2: :   0%|          | 1/200000 [00:03<180:54:35,  3.26s/it]stage 2: :   0%|          | 1/200000 [00:03<180:54:35,  3.26s/it, loss=0.214]<=============================== step 1  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2915], device='cuda:0')
subjects: ['horse']
controlnet: [True]
prompts: ['a photo of a bnha on a rocky cliff overlooking a vast ocean\n', 'a photo of a horse']
stage 2: :   0%|          | 1/200000 [00:03<180:54:35,  3.26s/it, loss=0.214]stage 2: :   0%|          | 2/200000 [00:04<115:30:55,  2.08s/it, loss=0.214]stage 2: :   0%|          | 2/200000 [00:04<115:30:55,  2.08s/it, loss=0.875]<=============================== step 2  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.6057], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a jeep']
stage 2: :   0%|          | 2/200000 [00:05<115:30:55,  2.08s/it, loss=0.875]stage 2: :   0%|          | 3/200000 [00:05<94:40:09,  1.70s/it, loss=0.875] stage 2: :   0%|          | 3/200000 [00:05<94:40:09,  1.70s/it, loss=0.73] <=============================== step 3  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.5236], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 3/200000 [00:06<94:40:09,  1.70s/it, loss=0.73]stage 2: :   0%|          | 4/200000 [00:06<83:50:22,  1.51s/it, loss=0.73]stage 2: :   0%|          | 4/200000 [00:06<83:50:22,  1.51s/it, loss=0.509]<=============================== step 4  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1868], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 4/200000 [00:07<83:50:22,  1.51s/it, loss=0.509]stage 2: :   0%|          | 5/200000 [00:08<77:14:04,  1.39s/it, loss=0.509]stage 2: :   0%|          | 5/200000 [00:08<77:14:04,  1.39s/it, loss=0.487]<=============================== step 5  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7104], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 5/200000 [00:08<77:14:04,  1.39s/it, loss=0.487]stage 2: :   0%|          | 6/200000 [00:09<73:13:27,  1.32s/it, loss=0.487]stage 2: :   0%|          | 6/200000 [00:09<73:13:27,  1.32s/it, loss=0.455]<=============================== step 6  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.9322], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 6/200000 [00:09<73:13:27,  1.32s/it, loss=0.455]stage 2: :   0%|          | 7/200000 [00:10<70:24:53,  1.27s/it, loss=0.455]stage 2: :   0%|          | 7/200000 [00:10<70:24:53,  1.27s/it, loss=0.438]<=============================== step 7  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0737], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 7/200000 [00:11<70:24:53,  1.27s/it, loss=0.438]stage 2: :   0%|          | 8/200000 [00:11<68:36:23,  1.23s/it, loss=0.438]stage 2: :   0%|          | 8/200000 [00:11<68:36:23,  1.23s/it, loss=0.425]<=============================== step 8  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4784], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 8/200000 [00:12<68:36:23,  1.23s/it, loss=0.425]stage 2: :   0%|          | 9/200000 [00:12<67:32:30,  1.22s/it, loss=0.425]stage 2: :   0%|          | 9/200000 [00:12<67:32:30,  1.22s/it, loss=0.36] <=============================== step 9  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1067], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 9/200000 [00:13<67:32:30,  1.22s/it, loss=0.36]stage 2: :   0%|          | 10/200000 [00:14<68:19:09,  1.23s/it, loss=0.36]stage 2: :   0%|          | 10/200000 [00:14<68:19:09,  1.23s/it, loss=0.688]<=============================== step 10  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2237], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 10/200000 [00:14<68:19:09,  1.23s/it, loss=0.688]stage 2: :   0%|          | 11/200000 [00:15<68:19:47,  1.23s/it, loss=0.688]stage 2: :   0%|          | 11/200000 [00:15<68:19:47,  1.23s/it, loss=0.488]<=============================== step 11  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9444], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 11/200000 [00:15<68:19:47,  1.23s/it, loss=0.488]stage 2: :   0%|          | 12/200000 [00:16<67:38:36,  1.22s/it, loss=0.488]stage 2: :   0%|          | 12/200000 [00:16<67:38:36,  1.22s/it, loss=0.261]<=============================== step 12  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8992], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 12/200000 [00:17<67:38:36,  1.22s/it, loss=0.261]stage 2: :   0%|          | 13/200000 [00:17<67:09:00,  1.21s/it, loss=0.261]stage 2: :   0%|          | 13/200000 [00:17<67:09:00,  1.21s/it, loss=0.479]<=============================== step 13  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1396], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 13/200000 [00:18<67:09:00,  1.21s/it, loss=0.479]stage 2: :   0%|          | 14/200000 [00:18<66:50:22,  1.20s/it, loss=0.479]stage 2: :   0%|          | 14/200000 [00:18<66:50:22,  1.20s/it, loss=0.701]<=============================== step 14  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9690], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 14/200000 [00:19<66:50:22,  1.20s/it, loss=0.701]stage 2: :   0%|          | 15/200000 [00:20<69:04:19,  1.24s/it, loss=0.701]stage 2: :   0%|          | 15/200000 [00:20<69:04:19,  1.24s/it, loss=0.554]<=============================== step 15  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1087], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 15/200000 [00:20<69:04:19,  1.24s/it, loss=0.554]stage 2: :   0%|          | 16/200000 [00:21<67:39:40,  1.22s/it, loss=0.554]stage 2: :   0%|          | 16/200000 [00:21<67:39:40,  1.22s/it, loss=0.43] <=============================== step 16  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9794], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 16/200000 [00:21<67:39:40,  1.22s/it, loss=0.43]stage 2: :   0%|          | 17/200000 [00:22<67:20:22,  1.21s/it, loss=0.43]stage 2: :   0%|          | 17/200000 [00:22<67:20:22,  1.21s/it, loss=0.387]<=============================== step 17  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4105], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 17/200000 [00:23<67:20:22,  1.21s/it, loss=0.387]stage 2: :   0%|          | 18/200000 [00:23<67:04:09,  1.21s/it, loss=0.387]stage 2: :   0%|          | 18/200000 [00:23<67:04:09,  1.21s/it, loss=0.536]<=============================== step 18  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5133], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 18/200000 [00:24<67:04:09,  1.21s/it, loss=0.536]stage 2: :   0%|          | 19/200000 [00:24<66:57:54,  1.21s/it, loss=0.536]stage 2: :   0%|          | 19/200000 [00:24<66:57:54,  1.21s/it, loss=0.376]<=============================== step 19  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 19/200000 [00:25<66:57:54,  1.21s/it, loss=0.376]stage 2: :   0%|          | 20/200000 [00:26<67:40:31,  1.22s/it, loss=0.376]stage 2: :   0%|          | 20/200000 [00:26<67:40:31,  1.22s/it, loss=0.558]<=============================== step 20  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2443], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ["a photo of a bnha at a river's edge with stones scattered around\n", 'a photo of a bus']
stage 2: :   0%|          | 20/200000 [00:26<67:40:31,  1.22s/it, loss=0.558]stage 2: :   0%|          | 21/200000 [00:27<68:29:16,  1.23s/it, loss=0.558]stage 2: :   0%|          | 21/200000 [00:27<68:29:16,  1.23s/it, loss=0.821]<=============================== step 21  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2812], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 21/200000 [00:28<68:29:16,  1.23s/it, loss=0.821]stage 2: :   0%|          | 22/200000 [00:28<67:59:44,  1.22s/it, loss=0.821]stage 2: :   0%|          | 22/200000 [00:28<67:59:44,  1.22s/it, loss=0.361]<=============================== step 22  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 22/200000 [00:29<67:59:44,  1.22s/it, loss=0.361]stage 2: :   0%|          | 23/200000 [00:29<66:49:58,  1.20s/it, loss=0.361]stage 2: :   0%|          | 23/200000 [00:29<66:49:58,  1.20s/it, loss=0.49] <=============================== step 23  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5010], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 23/200000 [00:30<66:49:58,  1.20s/it, loss=0.49]stage 2: :   0%|          | 24/200000 [00:31<71:38:44,  1.29s/it, loss=0.49]stage 2: :   0%|          | 24/200000 [00:31<71:38:44,  1.29s/it, loss=0.377]<=============================== step 24  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.1293], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 24/200000 [00:32<71:38:44,  1.29s/it, loss=0.377]stage 2: :   0%|          | 25/200000 [00:32<76:01:32,  1.37s/it, loss=0.377]stage 2: :   0%|          | 25/200000 [00:32<76:01:32,  1.37s/it, loss=0.38] <=============================== step 25  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7596], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 25/200000 [00:33<76:01:32,  1.37s/it, loss=0.38]stage 2: :   0%|          | 26/200000 [00:34<79:15:24,  1.43s/it, loss=0.38]stage 2: :   0%|          | 26/200000 [00:34<79:15:24,  1.43s/it, loss=0.53]<=============================== step 26  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 26/200000 [00:35<79:15:24,  1.43s/it, loss=0.53]stage 2: :   0%|          | 27/200000 [00:36<81:23:07,  1.47s/it, loss=0.53]stage 2: :   0%|          | 27/200000 [00:36<81:23:07,  1.47s/it, loss=0.444]<=============================== step 27  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4086], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 27/200000 [00:36<81:23:07,  1.47s/it, loss=0.444]stage 2: :   0%|          | 28/200000 [00:37<83:05:46,  1.50s/it, loss=0.444]stage 2: :   0%|          | 28/200000 [00:37<83:05:46,  1.50s/it, loss=0.443]<=============================== step 28  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7802], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 28/200000 [00:38<83:05:46,  1.50s/it, loss=0.443]stage 2: :   0%|          | 29/200000 [00:39<84:58:46,  1.53s/it, loss=0.443]stage 2: :   0%|          | 29/200000 [00:39<84:58:46,  1.53s/it, loss=0.315]<=============================== step 29  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 29/200000 [00:39<84:58:46,  1.53s/it, loss=0.315]stage 2: :   0%|          | 30/200000 [00:40<84:58:36,  1.53s/it, loss=0.315]stage 2: :   0%|          | 30/200000 [00:40<84:58:36,  1.53s/it, loss=0.402]<=============================== step 30  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 30/200000 [00:41<84:58:36,  1.53s/it, loss=0.402]stage 2: :   0%|          | 31/200000 [00:42<85:22:31,  1.54s/it, loss=0.402]stage 2: :   0%|          | 31/200000 [00:42<85:22:31,  1.54s/it, loss=0.243]<=============================== step 31  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.6180], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 31/200000 [00:43<85:22:31,  1.54s/it, loss=0.243]stage 2: :   0%|          | 32/200000 [00:43<85:59:33,  1.55s/it, loss=0.243]stage 2: :   0%|          | 32/200000 [00:43<85:59:33,  1.55s/it, loss=0.625]<=============================== step 32  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2689], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 32/200000 [00:44<85:59:33,  1.55s/it, loss=0.625]stage 2: :   0%|          | 33/200000 [00:45<85:59:39,  1.55s/it, loss=0.625]stage 2: :   0%|          | 33/200000 [00:45<85:59:39,  1.55s/it, loss=0.224]<=============================== step 33  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3038], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 33/200000 [00:46<85:59:39,  1.55s/it, loss=0.224]stage 2: :   0%|          | 34/200000 [00:47<90:42:36,  1.63s/it, loss=0.224]stage 2: :   0%|          | 34/200000 [00:47<90:42:36,  1.63s/it, loss=0.329]<=============================== step 34  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4907], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 34/200000 [00:48<90:42:36,  1.63s/it, loss=0.329]stage 2: :   0%|          | 35/200000 [00:48<90:13:52,  1.62s/it, loss=0.329]stage 2: :   0%|          | 35/200000 [00:48<90:13:52,  1.62s/it, loss=0.605]<=============================== step 35  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7699], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 35/200000 [00:49<90:13:52,  1.62s/it, loss=0.605]stage 2: :   0%|          | 36/200000 [00:50<89:38:21,  1.61s/it, loss=0.605]stage 2: :   0%|          | 36/200000 [00:50<89:38:21,  1.61s/it, loss=0.407]<=============================== step 36  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9095], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 36/200000 [00:51<89:38:21,  1.61s/it, loss=0.407]stage 2: :   0%|          | 37/200000 [00:52<89:43:24,  1.62s/it, loss=0.407]stage 2: :   0%|          | 37/200000 [00:52<89:43:24,  1.62s/it, loss=0.694]<=============================== step 37  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1313], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 37/200000 [00:52<89:43:24,  1.62s/it, loss=0.694]stage 2: :   0%|          | 38/200000 [00:53<89:09:23,  1.61s/it, loss=0.694]stage 2: :   0%|          | 38/200000 [00:53<89:09:23,  1.61s/it, loss=0.387]<=============================== step 38  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7227], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 38/200000 [00:54<89:09:23,  1.61s/it, loss=0.387]stage 2: :   0%|          | 39/200000 [00:55<88:38:18,  1.60s/it, loss=0.387]stage 2: :   0%|          | 39/200000 [00:55<88:38:18,  1.60s/it, loss=0.544]<=============================== step 39  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 39/200000 [00:56<88:38:18,  1.60s/it, loss=0.544]stage 2: :   0%|          | 40/200000 [00:56<88:45:39,  1.60s/it, loss=0.544]stage 2: :   0%|          | 40/200000 [00:56<88:45:39,  1.60s/it, loss=0.531]<=============================== step 40  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1765], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a cat']
stage 2: :   0%|          | 40/200000 [00:57<88:45:39,  1.60s/it, loss=0.531]stage 2: :   0%|          | 41/200000 [00:58<88:41:48,  1.60s/it, loss=0.531]stage 2: :   0%|          | 41/200000 [00:58<88:41:48,  1.60s/it, loss=1]    <=============================== step 41  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.5934], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 41/200000 [00:59<88:41:48,  1.60s/it, loss=1]stage 2: :   0%|          | 42/200000 [00:59<88:37:32,  1.60s/it, loss=1]stage 2: :   0%|          | 42/200000 [01:00<88:37:32,  1.60s/it, loss=0.521]<=============================== step 42  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3756], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ['a photo of a bnha on a rocky cliff overlooking a vast ocean\n', 'a photo of a pickup truck']
stage 2: :   0%|          | 42/200000 [01:00<88:37:32,  1.60s/it, loss=0.521]stage 2: :   0%|          | 43/200000 [01:01<88:14:32,  1.59s/it, loss=0.521]stage 2: :   0%|          | 43/200000 [01:01<88:14:32,  1.59s/it, loss=0.597]<=============================== step 43  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8029], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 43/200000 [01:02<88:14:32,  1.59s/it, loss=0.597]stage 2: :   0%|          | 44/200000 [01:03<87:27:34,  1.57s/it, loss=0.597]stage 2: :   0%|          | 44/200000 [01:03<87:27:34,  1.57s/it, loss=0.253]<=============================== step 44  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2812], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 44/200000 [01:03<87:27:34,  1.57s/it, loss=0.253]stage 2: :   0%|          | 45/200000 [01:04<88:10:39,  1.59s/it, loss=0.253]stage 2: :   0%|          | 45/200000 [01:04<88:10:39,  1.59s/it, loss=0.493]<=============================== step 45  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5359], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 45/200000 [01:05<88:10:39,  1.59s/it, loss=0.493]stage 2: :   0%|          | 46/200000 [01:06<87:37:44,  1.58s/it, loss=0.493]stage 2: :   0%|          | 46/200000 [01:06<87:37:44,  1.58s/it, loss=0.465]<=============================== step 46  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5029], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 46/200000 [01:07<87:37:44,  1.58s/it, loss=0.465]stage 2: :   0%|          | 47/200000 [01:07<88:30:25,  1.59s/it, loss=0.465]stage 2: :   0%|          | 47/200000 [01:07<88:30:25,  1.59s/it, loss=0.226]<=============================== step 47  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.5236], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 47/200000 [01:08<88:30:25,  1.59s/it, loss=0.226]stage 2: :   0%|          | 48/200000 [01:09<88:23:28,  1.59s/it, loss=0.226]stage 2: :   0%|          | 48/200000 [01:09<88:23:28,  1.59s/it, loss=0.376]<=============================== step 48  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2689], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha in a dense rainforest, with sunlight streaming through the canopy\n', 'a photo of a lion']
stage 2: :   0%|          | 48/200000 [01:10<88:23:28,  1.59s/it, loss=0.376]stage 2: :   0%|          | 49/200000 [01:11<89:11:24,  1.61s/it, loss=0.376]stage 2: :   0%|          | 49/200000 [01:11<89:11:24,  1.61s/it, loss=0.627]<=============================== step 49  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6775], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 49/200000 [01:11<89:11:24,  1.61s/it, loss=0.627]stage 2: :   0%|          | 50/200000 [01:12<88:58:59,  1.60s/it, loss=0.627]stage 2: :   0%|          | 50/200000 [01:12<88:58:59,  1.60s/it, loss=0.242]<=============================== step 50  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5359], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 50/200000 [01:13<88:58:59,  1.60s/it, loss=0.242]stage 2: :   0%|          | 51/200000 [01:14<88:16:08,  1.59s/it, loss=0.242]stage 2: :   0%|          | 51/200000 [01:14<88:16:08,  1.59s/it, loss=0.478]<=============================== step 51  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7001], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 51/200000 [01:15<88:16:08,  1.59s/it, loss=0.478]stage 2: :   0%|          | 52/200000 [01:15<87:33:04,  1.58s/it, loss=0.478]stage 2: :   0%|          | 52/200000 [01:15<87:33:04,  1.58s/it, loss=0.22] <=============================== step 52  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1436], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha in space with the Milky Way galaxy stretching across the background ', 'a photo of a cat']
stage 2: :   0%|          | 52/200000 [01:16<87:33:04,  1.58s/it, loss=0.22]stage 2: :   0%|          | 53/200000 [01:17<88:14:21,  1.59s/it, loss=0.22]stage 2: :   0%|          | 53/200000 [01:17<88:14:21,  1.59s/it, loss=0.514]<=============================== step 53  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1313], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a bus']
stage 2: :   0%|          | 53/200000 [01:18<88:14:21,  1.59s/it, loss=0.514]stage 2: :   0%|          | 54/200000 [01:19<93:09:41,  1.68s/it, loss=0.514]stage 2: :   0%|          | 54/200000 [01:19<93:09:41,  1.68s/it, loss=0.865]<=============================== step 54  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3491], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 54/200000 [01:20<93:09:41,  1.68s/it, loss=0.865]stage 2: :   0%|          | 55/200000 [01:20<91:11:08,  1.64s/it, loss=0.865]stage 2: :   0%|          | 55/200000 [01:20<91:11:08,  1.64s/it, loss=0.334]<=============================== step 55  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4558], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 55/200000 [01:21<91:11:08,  1.64s/it, loss=0.334]stage 2: :   0%|          | 56/200000 [01:22<90:15:42,  1.63s/it, loss=0.334]stage 2: :   0%|          | 56/200000 [01:22<90:15:42,  1.63s/it, loss=0.348]<=============================== step 56  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.9671], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 56/200000 [01:23<90:15:42,  1.63s/it, loss=0.348]stage 2: :   0%|          | 57/200000 [01:24<90:14:22,  1.62s/it, loss=0.348]stage 2: :   0%|          | 57/200000 [01:24<90:14:22,  1.62s/it, loss=0.614]<=============================== step 57  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0841], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 57/200000 [01:25<90:14:22,  1.62s/it, loss=0.614]stage 2: :   0%|          | 58/200000 [01:25<91:11:56,  1.64s/it, loss=0.614]stage 2: :   0%|          | 58/200000 [01:25<91:11:56,  1.64s/it, loss=0.537]<=============================== step 58  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2915], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha in a serene Japanese garden, surrounded by cherry blossoms\n', 'a photo of a cat']
stage 2: :   0%|          | 58/200000 [01:26<91:11:56,  1.64s/it, loss=0.537]stage 2: :   0%|          | 59/200000 [01:27<89:48:52,  1.62s/it, loss=0.537]stage 2: :   0%|          | 59/200000 [01:27<89:48:52,  1.62s/it, loss=0.815]<=============================== step 59  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 59/200000 [01:28<89:48:52,  1.62s/it, loss=0.815]stage 2: :   0%|          | 60/200000 [01:28<89:12:06,  1.61s/it, loss=0.815]stage 2: :   0%|          | 60/200000 [01:28<89:12:06,  1.61s/it, loss=0.569]<=============================== step 60  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9218], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 60/200000 [01:29<89:12:06,  1.61s/it, loss=0.569]stage 2: :   0%|          | 61/200000 [01:30<88:35:48,  1.60s/it, loss=0.569]stage 2: :   0%|          | 61/200000 [01:30<88:35:48,  1.60s/it, loss=0.385]<=============================== step 61  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6077], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 61/200000 [01:31<88:35:48,  1.60s/it, loss=0.385]stage 2: :   0%|          | 62/200000 [01:32<88:24:15,  1.59s/it, loss=0.385]stage 2: :   0%|          | 62/200000 [01:32<88:24:15,  1.59s/it, loss=0.574]<=============================== step 62  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9095], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 62/200000 [01:32<88:24:15,  1.59s/it, loss=0.574]stage 2: :   0%|          | 63/200000 [01:33<88:14:41,  1.59s/it, loss=0.574]stage 2: :   0%|          | 63/200000 [01:33<88:14:41,  1.59s/it, loss=0.311]<=============================== step 63  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 63/200000 [01:34<88:14:41,  1.59s/it, loss=0.311]stage 2: :   0%|          | 64/200000 [01:35<87:13:59,  1.57s/it, loss=0.311]stage 2: :   0%|          | 64/200000 [01:35<87:13:59,  1.57s/it, loss=0.425]<=============================== step 64  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2340], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha in a serene Japanese garden, surrounded by cherry blossoms\n', 'a photo of a motorbike']
stage 2: :   0%|          | 64/200000 [01:36<87:13:59,  1.57s/it, loss=0.425]stage 2: :   0%|          | 65/200000 [01:36<87:52:55,  1.58s/it, loss=0.425]stage 2: :   0%|          | 65/200000 [01:36<87:52:55,  1.58s/it, loss=1.08] <=============================== step 65  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5482], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 65/200000 [01:37<87:52:55,  1.58s/it, loss=1.08]stage 2: :   0%|          | 66/200000 [01:38<87:18:34,  1.57s/it, loss=1.08]stage 2: :   0%|          | 66/200000 [01:38<87:18:34,  1.57s/it, loss=0.599]<=============================== step 66  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3633], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 66/200000 [01:39<87:18:34,  1.57s/it, loss=0.599]stage 2: :   0%|          | 67/200000 [01:39<87:19:03,  1.57s/it, loss=0.599]stage 2: :   0%|          | 67/200000 [01:39<87:19:03,  1.57s/it, loss=0.389]<=============================== step 67  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0595], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 67/200000 [01:40<87:19:03,  1.57s/it, loss=0.389]stage 2: :   0%|          | 68/200000 [01:41<87:48:48,  1.58s/it, loss=0.389]stage 2: :   0%|          | 68/200000 [01:41<87:48:48,  1.58s/it, loss=0.48] <=============================== step 68  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3058], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 68/200000 [01:42<87:48:48,  1.58s/it, loss=0.48]stage 2: :   0%|          | 69/200000 [01:43<87:16:10,  1.57s/it, loss=0.48]stage 2: :   0%|          | 69/200000 [01:43<87:16:10,  1.57s/it, loss=0.574]<=============================== step 69  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2793], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 69/200000 [01:43<87:16:10,  1.57s/it, loss=0.574]stage 2: :   0%|          | 70/200000 [01:44<86:51:16,  1.56s/it, loss=0.574]stage 2: :   0%|          | 70/200000 [01:44<86:51:16,  1.56s/it, loss=0.425]<=============================== step 70  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.0615], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 70/200000 [01:45<86:51:16,  1.56s/it, loss=0.425]stage 2: :   0%|          | 71/200000 [01:46<88:03:11,  1.59s/it, loss=0.425]stage 2: :   0%|          | 71/200000 [01:46<88:03:11,  1.59s/it, loss=0.485]<=============================== step 71  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3284], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 71/200000 [01:47<88:03:11,  1.59s/it, loss=0.485]stage 2: :   0%|          | 72/200000 [01:47<87:46:55,  1.58s/it, loss=0.485]stage 2: :   0%|          | 72/200000 [01:47<87:46:55,  1.58s/it, loss=0.545]<=============================== step 72  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0039], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 72/200000 [01:48<87:46:55,  1.58s/it, loss=0.545]stage 2: :   0%|          | 73/200000 [01:49<91:10:35,  1.64s/it, loss=0.545]stage 2: :   0%|          | 73/200000 [01:49<91:10:35,  1.64s/it, loss=0.336]<=============================== step 73  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 73/200000 [01:50<91:10:35,  1.64s/it, loss=0.336]stage 2: :   0%|          | 74/200000 [01:51<90:11:19,  1.62s/it, loss=0.336]stage 2: :   0%|          | 74/200000 [01:51<90:11:19,  1.62s/it, loss=0.36] <=============================== step 74  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3407], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 74/200000 [01:51<90:11:19,  1.62s/it, loss=0.36]stage 2: :   0%|          | 75/200000 [01:52<89:19:33,  1.61s/it, loss=0.36]stage 2: :   0%|          | 75/200000 [01:52<89:19:33,  1.61s/it, loss=0.427]<=============================== step 75  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 75/200000 [01:53<89:19:33,  1.61s/it, loss=0.427]stage 2: :   0%|          | 76/200000 [01:54<88:31:56,  1.59s/it, loss=0.427]stage 2: :   0%|          | 76/200000 [01:54<88:31:56,  1.59s/it, loss=0.489]<=============================== step 76  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9794], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 76/200000 [01:55<88:31:56,  1.59s/it, loss=0.489]stage 2: :   0%|          | 77/200000 [01:55<88:04:32,  1.59s/it, loss=0.489]stage 2: :   0%|          | 77/200000 [01:55<88:04:32,  1.59s/it, loss=0.297]<=============================== step 77  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 77/200000 [01:56<88:04:32,  1.59s/it, loss=0.297]stage 2: :   0%|          | 78/200000 [01:57<87:38:49,  1.58s/it, loss=0.297]stage 2: :   0%|          | 78/200000 [01:57<87:38:49,  1.58s/it, loss=0.311]<=============================== step 78  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 78/200000 [01:58<87:38:49,  1.58s/it, loss=0.311]stage 2: :   0%|          | 79/200000 [01:59<88:00:21,  1.58s/it, loss=0.311]stage 2: :   0%|          | 79/200000 [01:59<88:00:21,  1.58s/it, loss=0.563]<=============================== step 79  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.1190], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 79/200000 [01:59<88:00:21,  1.58s/it, loss=0.563]stage 2: :   0%|          | 80/200000 [02:00<88:13:33,  1.59s/it, loss=0.563]stage 2: :   0%|          | 80/200000 [02:00<88:13:33,  1.59s/it, loss=0.411]<=============================== step 80  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 80/200000 [02:01<88:13:33,  1.59s/it, loss=0.411]stage 2: :   0%|          | 81/200000 [02:02<88:22:17,  1.59s/it, loss=0.411]stage 2: :   0%|          | 81/200000 [02:02<88:22:17,  1.59s/it, loss=0.597]<=============================== step 81  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5379], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 81/200000 [02:03<88:22:17,  1.59s/it, loss=0.597]stage 2: :   0%|          | 82/200000 [02:03<88:13:46,  1.59s/it, loss=0.597]stage 2: :   0%|          | 82/200000 [02:03<88:13:46,  1.59s/it, loss=0.523]<=============================== step 82  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0718], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 82/200000 [02:04<88:13:46,  1.59s/it, loss=0.523]stage 2: :   0%|          | 83/200000 [02:05<88:14:50,  1.59s/it, loss=0.523]stage 2: :   0%|          | 83/200000 [02:05<88:14:50,  1.59s/it, loss=0.606]<=============================== step 83  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1396], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 83/200000 [02:06<88:14:50,  1.59s/it, loss=0.606]stage 2: :   0%|          | 84/200000 [02:06<87:35:39,  1.58s/it, loss=0.606]stage 2: :   0%|          | 84/200000 [02:06<87:35:39,  1.58s/it, loss=0.61] <=============================== step 84  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2094], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha on a rocky cliff overlooking a vast ocean\n', 'a photo of a jeep']
stage 2: :   0%|          | 84/200000 [02:07<87:35:39,  1.58s/it, loss=0.61]stage 2: :   0%|          | 85/200000 [02:08<88:57:07,  1.60s/it, loss=0.61]stage 2: :   0%|          | 85/200000 [02:08<88:57:07,  1.60s/it, loss=0.741]<=============================== step 85  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 85/200000 [02:09<88:57:07,  1.60s/it, loss=0.741]stage 2: :   0%|          | 86/200000 [02:10<88:07:45,  1.59s/it, loss=0.741]stage 2: :   0%|          | 86/200000 [02:10<88:07:45,  1.59s/it, loss=0.641]<=============================== step 86  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9425], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 86/200000 [02:11<88:07:45,  1.59s/it, loss=0.641]stage 2: :   0%|          | 87/200000 [02:11<88:21:34,  1.59s/it, loss=0.641]stage 2: :   0%|          | 87/200000 [02:11<88:21:34,  1.59s/it, loss=0.835]<=============================== step 87  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 87/200000 [02:12<88:21:34,  1.59s/it, loss=0.835]stage 2: :   0%|          | 88/200000 [02:13<87:44:54,  1.58s/it, loss=0.835]stage 2: :   0%|          | 88/200000 [02:13<87:44:54,  1.58s/it, loss=0.415]<=============================== step 88  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.8520], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha in space with the Milky Way galaxy stretching across the background ', 'a photo of a jeep']
stage 2: :   0%|          | 88/200000 [02:14<87:44:54,  1.58s/it, loss=0.415]slurmstepd: error: *** JOB 307 ON cn3 CANCELLED AT 2024-08-21T12:01:42 ***
W0821 12:01:42.976548 139629139195712 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGTERM death signal, shutting down workers
W0821 12:01:42.996138 139629139195712 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2374475 closing signal SIGTERM
Traceback (most recent call last):
  File "/home/rishubhp/miniconda3/envs/contwords/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/accelerate/commands/launch.py", line 914, in launch_command
    multi_gpu_launcher(args)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/accelerate/commands/launch.py", line 603, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 835, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 79, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2374469 got signal: 15
