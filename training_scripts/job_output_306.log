/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
wandb: Currently logged in as: vaibhav-agrawal (vaibhav-agrawal-19). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/rishubhp/.netrc
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/rishubhp/vaibhav/meesho-project/training_scripts/wandb/run-20240821_115130-k601c5ec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run poseonly_subjectinprompt
wandb: ⭐️ View project at https://wandb.ai/vaibhav-agrawal-19/iisc
wandb: 🚀 View run at https://wandb.ai/vaibhav-agrawal-19/iisc/runs/k601c5ec
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
  0%|          | 0/200000 [00:00<?, ?it/s]<=============================== step 0  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9425], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a cat']
stage 2: :   0%|          | 0/200000 [00:02<?, ?it/s]stage 2: :   0%|          | 4/200000 [00:04<56:55:27,  1.02s/it]stage 2: :   0%|          | 4/200000 [00:04<56:55:27,  1.02s/it, loss=0.438]<=============================== step 4  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3840], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 4/200000 [00:04<56:55:27,  1.02s/it, loss=0.438]stage 2: :   0%|          | 8/200000 [00:05<37:01:13,  1.50it/s, loss=0.438]stage 2: :   0%|          | 8/200000 [00:05<37:01:13,  1.50it/s, loss=0.557]<=============================== step 8  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8274], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 8/200000 [00:06<37:01:13,  1.50it/s, loss=0.557]stage 2: :   0%|          | 12/200000 [00:07<30:12:18,  1.84it/s, loss=0.557]stage 2: :   0%|          | 12/200000 [00:07<30:12:18,  1.84it/s, loss=0.534]<=============================== step 12  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 12/200000 [00:08<30:12:18,  1.84it/s, loss=0.534]stage 2: :   0%|          | 16/200000 [00:08<27:07:13,  2.05it/s, loss=0.534]stage 2: :   0%|          | 16/200000 [00:08<27:07:13,  2.05it/s, loss=0.46] <=============================== step 16  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a cat']
stage 2: :   0%|          | 16/200000 [00:09<27:07:13,  2.05it/s, loss=0.46]stage 2: :   0%|          | 20/200000 [00:10<25:50:26,  2.15it/s, loss=0.46]stage 2: :   0%|          | 20/200000 [00:10<25:50:26,  2.15it/s, loss=0.594]<=============================== step 20  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6283], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 20/200000 [00:11<25:50:26,  2.15it/s, loss=0.594]stage 2: :   0%|          | 24/200000 [00:12<24:50:38,  2.24it/s, loss=0.594]stage 2: :   0%|          | 24/200000 [00:12<24:50:38,  2.24it/s, loss=0.315]<=============================== step 24  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.6303], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 24/200000 [00:13<24:50:38,  2.24it/s, loss=0.315]stage 2: :   0%|          | 28/200000 [00:13<23:58:41,  2.32it/s, loss=0.315]stage 2: :   0%|          | 28/200000 [00:13<23:58:41,  2.32it/s, loss=0.478]<=============================== step 28  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3859], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 28/200000 [00:14<23:58:41,  2.32it/s, loss=0.478]stage 2: :   0%|          | 32/200000 [00:15<23:21:01,  2.38it/s, loss=0.478]stage 2: :   0%|          | 32/200000 [00:15<23:21:01,  2.38it/s, loss=0.604]<=============================== step 32  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1662], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 32/200000 [00:16<23:21:01,  2.38it/s, loss=0.604]stage 2: :   0%|          | 36/200000 [00:17<23:02:30,  2.41it/s, loss=0.604]stage 2: :   0%|          | 36/200000 [00:17<23:02:30,  2.41it/s, loss=0.692]<=============================== step 36  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 36/200000 [00:17<23:02:30,  2.41it/s, loss=0.692]stage 2: :   0%|          | 40/200000 [00:18<22:14:58,  2.50it/s, loss=0.692]stage 2: :   0%|          | 40/200000 [00:18<22:14:58,  2.50it/s, loss=0.525]<=============================== step 40  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9690], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 40/200000 [00:19<22:14:58,  2.50it/s, loss=0.525]stage 2: :   0%|          | 44/200000 [00:20<21:56:05,  2.53it/s, loss=0.525]stage 2: :   0%|          | 44/200000 [00:20<21:56:05,  2.53it/s, loss=0.465]<=============================== step 44  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant on a rocky cliff overlooking a vast ocean\n', 'a photo of a elephant']
stage 2: :   0%|          | 44/200000 [00:20<21:56:05,  2.53it/s, loss=0.465]stage 2: :   0%|          | 48/200000 [00:21<21:59:47,  2.53it/s, loss=0.465]stage 2: :   0%|          | 48/200000 [00:21<21:59:47,  2.53it/s, loss=0.579]<=============================== step 48  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8727], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 48/200000 [00:22<21:59:47,  2.53it/s, loss=0.579]stage 2: :   0%|          | 52/200000 [00:23<21:42:06,  2.56it/s, loss=0.579]stage 2: :   0%|          | 52/200000 [00:23<21:42:06,  2.56it/s, loss=0.478]<=============================== step 52  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2793], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ["a photo of a bnha lion at a river's edge with stones scattered around\n", 'a photo of a lion']
stage 2: :   0%|          | 52/200000 [00:24<21:42:06,  2.56it/s, loss=0.478]stage 2: :   0%|          | 56/200000 [00:24<21:53:10,  2.54it/s, loss=0.478]stage 2: :   0%|          | 56/200000 [00:24<21:53:10,  2.54it/s, loss=0.539]<=============================== step 56  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3510], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 56/200000 [00:25<21:53:10,  2.54it/s, loss=0.539]stage 2: :   0%|          | 60/200000 [00:26<22:45:33,  2.44it/s, loss=0.539]stage 2: :   0%|          | 60/200000 [00:26<22:45:33,  2.44it/s, loss=0.583]<=============================== step 60  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8972], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a cat']
stage 2: :   0%|          | 60/200000 [00:27<22:45:33,  2.44it/s, loss=0.583]stage 2: :   0%|          | 64/200000 [00:28<22:20:50,  2.49it/s, loss=0.583]stage 2: :   0%|          | 64/200000 [00:28<22:20:50,  2.49it/s, loss=0.568]<=============================== step 64  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1868], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 64/200000 [00:28<22:20:50,  2.49it/s, loss=0.568]stage 2: :   0%|          | 68/200000 [00:29<21:53:42,  2.54it/s, loss=0.568]stage 2: :   0%|          | 68/200000 [00:29<21:53:42,  2.54it/s, loss=0.623]<=============================== step 68  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 68/200000 [00:30<21:53:42,  2.54it/s, loss=0.623]stage 2: :   0%|          | 72/200000 [00:31<21:59:42,  2.52it/s, loss=0.623]stage 2: :   0%|          | 72/200000 [00:31<21:59:42,  2.52it/s, loss=0.669]<=============================== step 72  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 72/200000 [00:31<21:59:42,  2.52it/s, loss=0.669]stage 2: :   0%|          | 76/200000 [00:32<21:32:18,  2.58it/s, loss=0.669]stage 2: :   0%|          | 76/200000 [00:32<21:32:18,  2.58it/s, loss=0.555]<=============================== step 76  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1396], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 76/200000 [00:33<21:32:18,  2.58it/s, loss=0.555]stage 2: :   0%|          | 80/200000 [00:34<21:23:16,  2.60it/s, loss=0.555]stage 2: :   0%|          | 80/200000 [00:34<21:23:16,  2.60it/s, loss=0.401]<=============================== step 80  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 80/200000 [00:34<21:23:16,  2.60it/s, loss=0.401]stage 2: :   0%|          | 84/200000 [00:35<21:15:50,  2.61it/s, loss=0.401]stage 2: :   0%|          | 84/200000 [00:35<21:15:50,  2.61it/s, loss=0.454]<=============================== step 84  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1 seconds.), retrying request
stage 2: :   0%|          | 84/200000 [00:36<21:15:50,  2.61it/s, loss=0.454]stage 2: :   0%|          | 88/200000 [00:37<21:16:11,  2.61it/s, loss=0.454]stage 2: :   0%|          | 88/200000 [00:37<21:16:11,  2.61it/s, loss=0.654]<=============================== step 88  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 88/200000 [00:38<21:16:11,  2.61it/s, loss=0.654]stage 2: :   0%|          | 92/200000 [00:38<21:09:04,  2.63it/s, loss=0.654]stage 2: :   0%|          | 92/200000 [00:38<21:09:04,  2.63it/s, loss=0.444]<=============================== step 92  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8397], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 92/200000 [00:39<21:09:04,  2.63it/s, loss=0.444]stage 2: :   0%|          | 96/200000 [00:40<21:00:40,  2.64it/s, loss=0.444]stage 2: :   0%|          | 96/200000 [00:40<21:00:40,  2.64it/s, loss=0.649]<=============================== step 96  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1170], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 96/200000 [00:41<21:00:40,  2.64it/s, loss=0.649]stage 2: :   0%|          | 100/200000 [00:41<21:03:06,  2.64it/s, loss=0.649]/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
azimuth = 0.0
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.5
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/002.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/005.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/006.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/010.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/009.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/007.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/011.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/015.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/017.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/000.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
azimuth = 0.0
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.5
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha boat in a river'
subject_prompt = 'a photo of a bnha ship in a river'
subject_prompt = 'a photo of a bnha fish in a river'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/005.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/002.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/003.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/010.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/006.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/009.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/007.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/015.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/011.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/017.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_fish/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_boat/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_ship/000.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
azimuth = 0.0
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.5
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha pickup truck on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha dog on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha motorbike on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
subject_prompt = 'a photo of a bnha bus on a remote country road, surrounded by rolling hills, vast open fields and tall trees'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/001.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/003.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/002.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/000.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/007.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/004.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/006.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/005.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/011.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/008.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/010.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/009.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/015.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/012.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/001.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/016.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/000.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_dog/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_motorbike/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/017.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
azimuth = 0.0
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.5
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha truck on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha jeep on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha cat on a tropical beach, with palm trees swaying and waves crashing on the shore'
subject_prompt = 'a photo of a bnha horse on a tropical beach, with palm trees swaying and waves crashing on the shore'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/000.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/002.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/001.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/007.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/004.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/006.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/005.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/011.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/008.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/010.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/009.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/015.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/012.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/001.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/016.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/000.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_truck/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_cat/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/017.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
azimuth = 0.0
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.5
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha camel in a desert'
subject_prompt = 'a photo of a bnha pickup truck in a desert'
subject_prompt = 'a photo of a bnha bus in a desert'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/005.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/001.jpg']1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg']

2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/003.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/010.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/006.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/009.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/007.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/015.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/011.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/017.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_bus/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_camel/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
azimuth = 0.0
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.5
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha elephant in a forest'
subject_prompt = 'a photo of a bnha lion in a forest'
subject_prompt = 'a photo of a bnha jeep in a forest'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/002.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/001.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/005.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/010.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/006.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/009.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/007.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/015.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/015.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/011.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/011.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/013.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/014.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/014.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/012.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/013.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/016.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/017.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_jeep/017.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_elephant/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_lion/000.jpg']
every thread finished their generation, now collecting them to form a gif...
removing ../multiobject/__poseonly_subjectinprompt/outputs_100/tmp
stage 2: :   0%|          | 100/200000 [13:14<21:03:06,  2.64it/s, loss=0.508]<=============================== step 100  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ["a photo of a bnha cat at a river's edge with stones scattered around\n", 'a photo of a cat']
stage 2: :   0%|          | 100/200000 [13:14<21:03:06,  2.64it/s, loss=0.508]stage 2: :   0%|          | 104/200000 [13:15<3153:55:15, 56.80s/it, loss=0.508]stage 2: :   0%|          | 104/200000 [13:15<3153:55:15, 56.80s/it, loss=0.465]<=============================== step 104  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.0698], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 104/200000 [13:16<3153:55:15, 56.80s/it, loss=0.465]stage 2: :   0%|          | 108/200000 [13:16<2212:53:11, 39.85s/it, loss=0.465]stage 2: :   0%|          | 108/200000 [13:16<2212:53:11, 39.85s/it, loss=0.492]<=============================== step 108  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.6755], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 108/200000 [13:17<2212:53:11, 39.85s/it, loss=0.492]stage 2: :   0%|          | 112/200000 [13:18<1554:11:28, 27.99s/it, loss=0.492]stage 2: :   0%|          | 112/200000 [13:18<1554:11:28, 27.99s/it, loss=0.702]<=============================== step 112  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2689], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 112/200000 [13:18<1554:11:28, 27.99s/it, loss=0.702]stage 2: :   0%|          | 116/200000 [13:19<1093:20:23, 19.69s/it, loss=0.702]stage 2: :   0%|          | 116/200000 [13:19<1093:20:23, 19.69s/it, loss=0.446]<=============================== step 116  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6077], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 116/200000 [13:20<1093:20:23, 19.69s/it, loss=0.446]stage 2: :   0%|          | 120/200000 [13:20<771:04:15, 13.89s/it, loss=0.446] stage 2: :   0%|          | 120/200000 [13:20<771:04:15, 13.89s/it, loss=0.565]<=============================== step 120  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2915], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 120/200000 [13:21<771:04:15, 13.89s/it, loss=0.565]stage 2: :   0%|          | 124/200000 [13:22<546:25:06,  9.84s/it, loss=0.565]stage 2: :   0%|          | 124/200000 [13:22<546:25:06,  9.84s/it, loss=0.384]<=============================== step 124  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5029], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 124/200000 [13:23<546:25:06,  9.84s/it, loss=0.384]stage 2: :   0%|          | 128/200000 [13:23<388:52:44,  7.00s/it, loss=0.384]stage 2: :   0%|          | 128/200000 [13:23<388:52:44,  7.00s/it, loss=0.574]<=============================== step 128  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4784], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 128/200000 [13:24<388:52:44,  7.00s/it, loss=0.574]stage 2: :   0%|          | 132/200000 [13:25<278:35:46,  5.02s/it, loss=0.574]stage 2: :   0%|          | 132/200000 [13:25<278:35:46,  5.02s/it, loss=0.407]<=============================== step 132  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8623], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 132/200000 [13:26<278:35:46,  5.02s/it, loss=0.407]stage 2: :   0%|          | 136/200000 [13:27<202:10:31,  3.64s/it, loss=0.407]stage 2: :   0%|          | 136/200000 [13:27<202:10:31,  3.64s/it, loss=0.655]<=============================== step 136  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4784], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 136/200000 [13:27<202:10:31,  3.64s/it, loss=0.655]stage 2: :   0%|          | 140/200000 [13:28<147:57:40,  2.67s/it, loss=0.655]stage 2: :   0%|          | 140/200000 [13:28<147:57:40,  2.67s/it, loss=0.532]<=============================== step 140  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6426], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 140/200000 [13:29<147:57:40,  2.67s/it, loss=0.532]stage 2: :   0%|          | 144/200000 [13:30<109:49:35,  1.98s/it, loss=0.532]stage 2: :   0%|          | 144/200000 [13:30<109:49:35,  1.98s/it, loss=0.572]<=============================== step 144  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a sunflower field under a clear blue sky\n', 'a photo of a motorbike']
stage 2: :   0%|          | 144/200000 [13:30<109:49:35,  1.98s/it, loss=0.572]stage 2: :   0%|          | 148/200000 [13:31<83:26:25,  1.50s/it, loss=0.572] stage 2: :   0%|          | 148/200000 [13:31<83:26:25,  1.50s/it, loss=0.668]<=============================== step 148  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 148/200000 [13:32<83:26:25,  1.50s/it, loss=0.668]stage 2: :   0%|          | 152/200000 [13:33<64:42:46,  1.17s/it, loss=0.668]stage 2: :   0%|          | 152/200000 [13:33<64:42:46,  1.17s/it, loss=0.61] <=============================== step 152  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2935], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 152/200000 [13:34<64:42:46,  1.17s/it, loss=0.61]stage 2: :   0%|          | 156/200000 [13:34<51:41:05,  1.07it/s, loss=0.61]stage 2: :   0%|          | 156/200000 [13:34<51:41:05,  1.07it/s, loss=0.434]<=============================== step 156  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5133], device='cuda:0')
subjects: ['horse']
controlnet: [True]
prompts: ['a photo of a bnha horse in space with the Milky Way galaxy stretching across the background ', 'a photo of a horse']
stage 2: :   0%|          | 156/200000 [13:35<51:41:05,  1.07it/s, loss=0.434]stage 2: :   0%|          | 160/200000 [13:36<42:43:24,  1.30it/s, loss=0.434]stage 2: :   0%|          | 160/200000 [13:36<42:43:24,  1.30it/s, loss=0.608]<=============================== step 160  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.0698], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 160/200000 [13:37<42:43:24,  1.30it/s, loss=0.608]stage 2: :   0%|          | 164/200000 [13:37<36:15:49,  1.53it/s, loss=0.608]stage 2: :   0%|          | 164/200000 [13:37<36:15:49,  1.53it/s, loss=0.373]<=============================== step 164  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5133], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 164/200000 [13:38<36:15:49,  1.53it/s, loss=0.373]stage 2: :   0%|          | 168/200000 [13:39<32:21:56,  1.72it/s, loss=0.373]stage 2: :   0%|          | 168/200000 [13:39<32:21:56,  1.72it/s, loss=0.56] <=============================== step 168  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1416], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 168/200000 [13:40<32:21:56,  1.72it/s, loss=0.56]stage 2: :   0%|          | 172/200000 [13:41<29:06:54,  1.91it/s, loss=0.56]stage 2: :   0%|          | 172/200000 [13:41<29:06:54,  1.91it/s, loss=0.563]<=============================== step 172  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 172/200000 [13:41<29:06:54,  1.91it/s, loss=0.563]stage 2: :   0%|          | 176/200000 [13:42<26:37:22,  2.08it/s, loss=0.563]stage 2: :   0%|          | 176/200000 [13:42<26:37:22,  2.08it/s, loss=0.474]<=============================== step 176  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant by a riverside with wildflowers blooming nearby\n', 'a photo of a elephant']
stage 2: :   0%|          | 176/200000 [13:43<26:37:22,  2.08it/s, loss=0.474]stage 2: :   0%|          | 180/200000 [13:44<25:01:35,  2.22it/s, loss=0.474]stage 2: :   0%|          | 180/200000 [13:44<25:01:35,  2.22it/s, loss=0.417]<=============================== step 180  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 180/200000 [13:44<25:01:35,  2.22it/s, loss=0.417]stage 2: :   0%|          | 184/200000 [13:45<23:58:17,  2.32it/s, loss=0.417]stage 2: :   0%|          | 184/200000 [13:45<23:58:17,  2.32it/s, loss=0.47] <=============================== step 184  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5029], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 184/200000 [13:46<23:58:17,  2.32it/s, loss=0.47]stage 2: :   0%|          | 188/200000 [13:47<23:06:03,  2.40it/s, loss=0.47]stage 2: :   0%|          | 188/200000 [13:47<23:06:03,  2.40it/s, loss=0.598]<=============================== step 188  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3387], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 188/200000 [13:48<23:06:03,  2.40it/s, loss=0.598]stage 2: :   0%|          | 192/200000 [13:48<22:40:10,  2.45it/s, loss=0.598]stage 2: :   0%|          | 192/200000 [13:48<22:40:10,  2.45it/s, loss=0.703]<=============================== step 192  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant on a rocky cliff overlooking a vast ocean\n', 'a photo of a elephant']
stage 2: :   0%|          | 192/200000 [13:49<22:40:10,  2.45it/s, loss=0.703]stage 2: :   0%|          | 196/200000 [13:50<22:34:27,  2.46it/s, loss=0.703]stage 2: :   0%|          | 196/200000 [13:50<22:34:27,  2.46it/s, loss=0.644]<=============================== step 196  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.8869], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 196/200000 [13:51<22:34:27,  2.46it/s, loss=0.644]stage 2: :   0%|          | 200/200000 [13:52<22:28:06,  2.47it/s, loss=0.644]stage 2: :   0%|          | 200/200000 [13:52<22:28:06,  2.47it/s, loss=0.417]<=============================== step 200  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3756], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant in a dense rainforest, with sunlight streaming through the canopy\n', 'a photo of a elephant']
stage 2: :   0%|          | 200/200000 [13:52<22:28:06,  2.47it/s, loss=0.417]stage 2: :   0%|          | 204/200000 [13:53<22:08:14,  2.51it/s, loss=0.417]stage 2: :   0%|          | 204/200000 [13:53<22:08:14,  2.51it/s, loss=0.53] <=============================== step 204  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7925], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 204/200000 [13:54<22:08:14,  2.51it/s, loss=0.53]stage 2: :   0%|          | 208/200000 [13:55<21:47:34,  2.55it/s, loss=0.53]stage 2: :   0%|          | 208/200000 [13:55<21:47:34,  2.55it/s, loss=0.455]<=============================== step 208  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.0615], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 208/200000 [13:55<21:47:34,  2.55it/s, loss=0.455]stage 2: :   0%|          | 212/200000 [13:56<22:16:19,  2.49it/s, loss=0.455]stage 2: :   0%|          | 212/200000 [13:56<22:16:19,  2.49it/s, loss=0.441]<=============================== step 212  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 212/200000 [13:57<22:16:19,  2.49it/s, loss=0.441]stage 2: :   0%|          | 216/200000 [13:58<21:52:53,  2.54it/s, loss=0.441]stage 2: :   0%|          | 216/200000 [13:58<21:52:53,  2.54it/s, loss=0.401]<=============================== step 216  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0595], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 216/200000 [13:59<21:52:53,  2.54it/s, loss=0.401]stage 2: :   0%|          | 220/200000 [13:59<21:45:27,  2.55it/s, loss=0.401]stage 2: :   0%|          | 220/200000 [13:59<21:45:27,  2.55it/s, loss=0.571]<=============================== step 220  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5010], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ["a photo of a bnha lion at a river's edge with stones scattered around\n", 'a photo of a lion']
stage 2: :   0%|          | 220/200000 [14:00<21:45:27,  2.55it/s, loss=0.571]stage 2: :   0%|          | 224/200000 [14:01<21:47:13,  2.55it/s, loss=0.571]stage 2: :   0%|          | 224/200000 [14:01<21:47:13,  2.55it/s, loss=0.812]<=============================== step 224  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4105], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 224/200000 [14:02<21:47:13,  2.55it/s, loss=0.812]stage 2: :   0%|          | 228/200000 [14:02<21:40:36,  2.56it/s, loss=0.812]stage 2: :   0%|          | 228/200000 [14:02<21:40:36,  2.56it/s, loss=0.569]<=============================== step 228  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a lush vineyard with rows of grapevines stretching into the distance\n', 'a photo of a lion']
stage 2: :   0%|          | 228/200000 [14:03<21:40:36,  2.56it/s, loss=0.569]stage 2: :   0%|          | 232/200000 [14:04<21:51:18,  2.54it/s, loss=0.569]stage 2: :   0%|          | 232/200000 [14:04<21:51:18,  2.54it/s, loss=0.632]<=============================== step 232  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2094], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a motorbike']
stage 2: :   0%|          | 232/200000 [14:05<21:51:18,  2.54it/s, loss=0.632]stage 2: :   0%|          | 236/200000 [14:06<21:49:29,  2.54it/s, loss=0.632]stage 2: :   0%|          | 236/200000 [14:06<21:49:29,  2.54it/s, loss=0.712]<=============================== step 236  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5482], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a jeep']
stage 2: :   0%|          | 236/200000 [14:06<21:49:29,  2.54it/s, loss=0.712]stage 2: :   0%|          | 240/200000 [14:07<21:45:05,  2.55it/s, loss=0.712]stage 2: :   0%|          | 240/200000 [14:07<21:45:05,  2.55it/s, loss=0.43] <=============================== step 240  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 240/200000 [14:08<21:45:05,  2.55it/s, loss=0.43]stage 2: :   0%|          | 244/200000 [14:09<21:39:09,  2.56it/s, loss=0.43]stage 2: :   0%|          | 244/200000 [14:09<21:39:09,  2.56it/s, loss=0.519]<=============================== step 244  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0492], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 244/200000 [14:09<21:39:09,  2.56it/s, loss=0.519]stage 2: :   0%|          | 248/200000 [14:10<21:37:40,  2.57it/s, loss=0.519]stage 2: :   0%|          | 248/200000 [14:10<21:37:40,  2.57it/s, loss=0.467]<=============================== step 248  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7227], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 248/200000 [14:11<21:37:40,  2.57it/s, loss=0.467]stage 2: :   0%|          | 252/200000 [14:12<21:20:44,  2.60it/s, loss=0.467]stage 2: :   0%|          | 252/200000 [14:12<21:20:44,  2.60it/s, loss=0.554]<=============================== step 252  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.0123], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 252/200000 [14:13<21:20:44,  2.60it/s, loss=0.554]stage 2: :   0%|          | 256/200000 [14:14<22:16:44,  2.49it/s, loss=0.554]stage 2: :   0%|          | 256/200000 [14:14<22:16:44,  2.49it/s, loss=0.483]<=============================== step 256  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9444], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 256/200000 [14:14<22:16:44,  2.49it/s, loss=0.483]stage 2: :   0%|          | 260/200000 [14:15<22:00:17,  2.52it/s, loss=0.483]stage 2: :   0%|          | 260/200000 [14:15<22:00:17,  2.52it/s, loss=0.408]<=============================== step 260  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.1293], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 260/200000 [14:16<22:00:17,  2.52it/s, loss=0.408]stage 2: :   0%|          | 264/200000 [14:17<21:58:30,  2.52it/s, loss=0.408]stage 2: :   0%|          | 264/200000 [14:17<21:58:30,  2.52it/s, loss=0.667]<=============================== step 264  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8972], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 264/200000 [14:17<21:58:30,  2.52it/s, loss=0.667]stage 2: :   0%|          | 268/200000 [14:18<21:47:00,  2.55it/s, loss=0.667]stage 2: :   0%|          | 268/200000 [14:18<21:47:00,  2.55it/s, loss=0.595]<=============================== step 268  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3265], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 268/200000 [14:19<21:47:00,  2.55it/s, loss=0.595]stage 2: :   0%|          | 272/200000 [14:20<21:40:47,  2.56it/s, loss=0.595]stage 2: :   0%|          | 272/200000 [14:20<21:40:47,  2.56it/s, loss=0.483]<=============================== step 272  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.0123], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 272/200000 [14:20<21:40:47,  2.56it/s, loss=0.483]stage 2: :   0%|          | 276/200000 [14:21<21:29:11,  2.58it/s, loss=0.483]stage 2: :   0%|          | 276/200000 [14:21<21:29:11,  2.58it/s, loss=0.48] <=============================== step 276  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 276/200000 [14:22<21:29:11,  2.58it/s, loss=0.48]stage 2: :   0%|          | 280/200000 [14:23<21:29:49,  2.58it/s, loss=0.48]stage 2: :   0%|          | 280/200000 [14:23<21:29:49,  2.58it/s, loss=0.899]<=============================== step 280  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0492], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 280/200000 [14:24<21:29:49,  2.58it/s, loss=0.899]stage 2: :   0%|          | 284/200000 [14:24<21:16:04,  2.61it/s, loss=0.899]stage 2: :   0%|          | 284/200000 [14:24<21:16:04,  2.61it/s, loss=0.595]<=============================== step 284  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2217], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 284/200000 [14:25<21:16:04,  2.61it/s, loss=0.595]stage 2: :   0%|          | 288/200000 [14:26<21:22:56,  2.59it/s, loss=0.595]stage 2: :   0%|          | 288/200000 [14:26<21:22:56,  2.59it/s, loss=0.54] <=============================== step 288  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.9322], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 288/200000 [14:27<21:22:56,  2.59it/s, loss=0.54]stage 2: :   0%|          | 292/200000 [14:28<22:13:02,  2.50it/s, loss=0.54]stage 2: :   0%|          | 292/200000 [14:28<22:13:02,  2.50it/s, loss=0.399]<=============================== step 292  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5482], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 292/200000 [14:28<22:13:02,  2.50it/s, loss=0.399]stage 2: :   0%|          | 296/200000 [14:29<21:51:57,  2.54it/s, loss=0.399]stage 2: :   0%|          | 296/200000 [14:29<21:51:57,  2.54it/s, loss=0.689]<=============================== step 296  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.1888], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 296/200000 [14:30<21:51:57,  2.54it/s, loss=0.689]stage 2: :   0%|          | 300/200000 [14:31<21:57:28,  2.53it/s, loss=0.689]stage 2: :   0%|          | 300/200000 [14:31<21:57:28,  2.53it/s, loss=0.545]<=============================== step 300  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0246], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat on a rocky cliff overlooking a vast ocean\n', 'a photo of a cat']
stage 2: :   0%|          | 300/200000 [14:31<21:57:28,  2.53it/s, loss=0.545]stage 2: :   0%|          | 304/200000 [14:32<21:51:52,  2.54it/s, loss=0.545]stage 2: :   0%|          | 304/200000 [14:32<21:51:52,  2.54it/s, loss=0.476]<=============================== step 304  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a lush vineyard with rows of grapevines stretching into the distance\n', 'a photo of a motorbike']
stage 2: :   0%|          | 304/200000 [14:33<21:51:52,  2.54it/s, loss=0.476]stage 2: :   0%|          | 308/200000 [14:34<21:56:57,  2.53it/s, loss=0.476]stage 2: :   0%|          | 308/200000 [14:34<21:56:57,  2.53it/s, loss=0.584]<=============================== step 308  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.0615], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 308/200000 [14:35<21:56:57,  2.53it/s, loss=0.584]stage 2: :   0%|          | 312/200000 [14:35<21:40:19,  2.56it/s, loss=0.584]stage 2: :   0%|          | 312/200000 [14:35<21:40:19,  2.56it/s, loss=0.551]<=============================== step 312  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 312/200000 [14:36<21:40:19,  2.56it/s, loss=0.551]stage 2: :   0%|          | 316/200000 [14:37<21:29:14,  2.58it/s, loss=0.551]stage 2: :   0%|          | 316/200000 [14:37<21:29:14,  2.58it/s, loss=0.529]<=============================== step 316  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.6549], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 316/200000 [14:38<21:29:14,  2.58it/s, loss=0.529]stage 2: :   0%|          | 320/200000 [14:38<21:28:35,  2.58it/s, loss=0.529]stage 2: :   0%|          | 320/200000 [14:38<21:28:35,  2.58it/s, loss=0.598]<=============================== step 320  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3840], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 320/200000 [14:39<21:28:35,  2.58it/s, loss=0.598]stage 2: :   0%|          | 324/200000 [14:40<21:46:28,  2.55it/s, loss=0.598]stage 2: :   0%|          | 324/200000 [14:40<21:46:28,  2.55it/s, loss=0.481]<=============================== step 324  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9076], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a motorbike']
stage 2: :   0%|          | 324/200000 [14:41<21:46:28,  2.55it/s, loss=0.481]stage 2: :   0%|          | 328/200000 [14:42<21:55:09,  2.53it/s, loss=0.481]stage 2: :   0%|          | 328/200000 [14:42<21:55:09,  2.53it/s, loss=0.54] <=============================== step 328  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7453], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a lion']
stage 2: :   0%|          | 328/200000 [14:42<21:55:09,  2.53it/s, loss=0.54]stage 2: :   0%|          | 332/200000 [14:43<21:54:43,  2.53it/s, loss=0.54]stage 2: :   0%|          | 332/200000 [14:43<21:54:43,  2.53it/s, loss=0.796]<=============================== step 332  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7247], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 332/200000 [14:44<21:54:43,  2.53it/s, loss=0.796]stage 2: :   0%|          | 336/200000 [14:45<21:40:48,  2.56it/s, loss=0.796]stage 2: :   0%|          | 336/200000 [14:45<21:40:48,  2.56it/s, loss=0.505]<=============================== step 336  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.4661], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 336/200000 [14:46<21:40:48,  2.56it/s, loss=0.505]stage 2: :   0%|          | 340/200000 [14:46<21:40:00,  2.56it/s, loss=0.505]stage 2: :   0%|          | 340/200000 [14:46<21:40:00,  2.56it/s, loss=0.697]<=============================== step 340  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3161], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 340/200000 [14:47<21:40:00,  2.56it/s, loss=0.697]stage 2: :   0%|          | 344/200000 [14:48<21:36:49,  2.57it/s, loss=0.697]stage 2: :   0%|          | 344/200000 [14:48<21:36:49,  2.57it/s, loss=0.387]<=============================== step 344  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4105], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 344/200000 [14:49<21:36:49,  2.57it/s, loss=0.387]stage 2: :   0%|          | 348/200000 [14:50<21:54:15,  2.53it/s, loss=0.387]stage 2: :   0%|          | 348/200000 [14:50<21:54:15,  2.53it/s, loss=0.5]  <=============================== step 348  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8746], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ["a photo of a bnha elephant at a river's edge with stones scattered around\n", 'a photo of a elephant']
stage 2: :   0%|          | 348/200000 [14:50<21:54:15,  2.53it/s, loss=0.5]stage 2: :   0%|          | 352/200000 [14:51<22:37:28,  2.45it/s, loss=0.5]stage 2: :   0%|          | 352/200000 [14:51<22:37:28,  2.45it/s, loss=0.652]<=============================== step 352  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7473], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 352/200000 [14:52<22:37:28,  2.45it/s, loss=0.652]stage 2: :   0%|          | 356/200000 [14:53<22:37:11,  2.45it/s, loss=0.652]stage 2: :   0%|          | 356/200000 [14:53<22:37:11,  2.45it/s, loss=0.609]<=============================== step 356  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8727], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 356/200000 [14:54<22:37:11,  2.45it/s, loss=0.609]stage 2: :   0%|          | 360/200000 [14:55<22:44:57,  2.44it/s, loss=0.609]stage 2: :   0%|          | 360/200000 [14:55<22:44:57,  2.44it/s, loss=0.491]<=============================== step 360  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0020], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 360/200000 [14:55<22:44:57,  2.44it/s, loss=0.491]stage 2: :   0%|          | 364/200000 [14:56<22:42:47,  2.44it/s, loss=0.491]stage 2: :   0%|          | 364/200000 [14:56<22:42:47,  2.44it/s, loss=0.513]<=============================== step 364  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9218], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 364/200000 [14:57<22:42:47,  2.44it/s, loss=0.513]stage 2: :   0%|          | 368/200000 [14:58<22:37:04,  2.45it/s, loss=0.513]stage 2: :   0%|          | 368/200000 [14:58<22:37:04,  2.45it/s, loss=0.46] <=============================== step 368  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.2483], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion by a riverside with wildflowers blooming nearby\n', 'a photo of a lion']
stage 2: :   0%|          | 368/200000 [14:59<22:37:04,  2.45it/s, loss=0.46]stage 2: :   0%|          | 372/200000 [15:00<23:53:12,  2.32it/s, loss=0.46]stage 2: :   0%|          | 372/200000 [15:00<23:53:12,  2.32it/s, loss=0.54]<=============================== step 372  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4435], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 372/200000 [15:01<23:53:12,  2.32it/s, loss=0.54]stage 2: :   0%|          | 376/200000 [15:01<22:59:35,  2.41it/s, loss=0.54]stage 2: :   0%|          | 376/200000 [15:01<22:59:35,  2.41it/s, loss=0.43]<=============================== step 376  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 376/200000 [15:02<22:59:35,  2.41it/s, loss=0.43]stage 2: :   0%|          | 380/200000 [15:03<21:38:20,  2.56it/s, loss=0.43]stage 2: :   0%|          | 380/200000 [15:03<21:38:20,  2.56it/s, loss=0.596]<=============================== step 380  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 380/200000 [15:03<21:38:20,  2.56it/s, loss=0.596]stage 2: :   0%|          | 384/200000 [15:04<20:30:30,  2.70it/s, loss=0.596]stage 2: :   0%|          | 384/200000 [15:04<20:30:30,  2.70it/s, loss=0.663]<=============================== step 384  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7001], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 384/200000 [15:04<20:30:30,  2.70it/s, loss=0.663]stage 2: :   0%|          | 388/200000 [15:05<19:42:13,  2.81it/s, loss=0.663]stage 2: :   0%|          | 388/200000 [15:05<19:42:13,  2.81it/s, loss=0.65] <=============================== step 388  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7247], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in a serene Japanese garden, surrounded by cherry blossoms\n', 'a photo of a jeep']
stage 2: :   0%|          | 388/200000 [15:06<19:42:13,  2.81it/s, loss=0.65]stage 2: :   0%|          | 392/200000 [15:07<19:27:44,  2.85it/s, loss=0.65]stage 2: :   0%|          | 392/200000 [15:07<19:27:44,  2.85it/s, loss=0.52]<=============================== step 392  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3491], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ['a photo of a bnha pickup truck in a dense rainforest, with sunlight streaming through the canopy\n', 'a photo of a pickup truck']
stage 2: :   0%|          | 392/200000 [15:07<19:27:44,  2.85it/s, loss=0.52]stage 2: :   0%|          | 396/200000 [15:08<19:10:01,  2.89it/s, loss=0.52]stage 2: :   0%|          | 396/200000 [15:08<19:10:01,  2.89it/s, loss=0.68]<=============================== step 396  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1313], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 396/200000 [15:09<19:10:01,  2.89it/s, loss=0.68]stage 2: :   0%|          | 400/200000 [15:09<19:15:43,  2.88it/s, loss=0.68]stage 2: :   0%|          | 400/200000 [15:09<19:15:43,  2.88it/s, loss=0.543]<=============================== step 400  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 400/200000 [15:10<19:15:43,  2.88it/s, loss=0.543]stage 2: :   0%|          | 404/200000 [15:11<18:44:35,  2.96it/s, loss=0.543]stage 2: :   0%|          | 404/200000 [15:11<18:44:35,  2.96it/s, loss=0.452]<=============================== step 404  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5482], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 404/200000 [15:11<18:44:35,  2.96it/s, loss=0.452]stage 2: :   0%|          | 408/200000 [15:12<18:34:51,  2.98it/s, loss=0.452]stage 2: :   0%|          | 408/200000 [15:12<18:34:51,  2.98it/s, loss=0.611]<=============================== step 408  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5954], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 408/200000 [15:12<18:34:51,  2.98it/s, loss=0.611]stage 2: :   0%|          | 412/200000 [15:13<18:31:23,  2.99it/s, loss=0.611]stage 2: :   0%|          | 412/200000 [15:13<18:31:23,  2.99it/s, loss=0.452]<=============================== step 412  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3756], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 412/200000 [15:14<18:31:23,  2.99it/s, loss=0.452]stage 2: :   0%|          | 416/200000 [15:14<18:21:21,  3.02it/s, loss=0.452]stage 2: :   0%|          | 416/200000 [15:15<18:21:21,  3.02it/s, loss=0.479]<=============================== step 416  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4907], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 416/200000 [15:15<18:21:21,  3.02it/s, loss=0.479]stage 2: :   0%|          | 420/200000 [15:16<18:16:15,  3.03it/s, loss=0.479]stage 2: :   0%|          | 420/200000 [15:16<18:16:15,  3.03it/s, loss=0.57] <=============================== step 420  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 420/200000 [15:16<18:16:15,  3.03it/s, loss=0.57]stage 2: :   0%|          | 424/200000 [15:17<18:16:08,  3.03it/s, loss=0.57]stage 2: :   0%|          | 424/200000 [15:17<18:16:08,  3.03it/s, loss=0.388]<=============================== step 424  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.6878], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 424/200000 [15:18<18:16:08,  3.03it/s, loss=0.388]stage 2: :   0%|          | 428/200000 [15:18<18:22:37,  3.02it/s, loss=0.388]stage 2: :   0%|          | 428/200000 [15:18<18:22:37,  3.02it/s, loss=0.428]<=============================== step 428  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8274], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 428/200000 [15:19<18:22:37,  3.02it/s, loss=0.428]stage 2: :   0%|          | 432/200000 [15:20<19:31:12,  2.84it/s, loss=0.428]stage 2: :   0%|          | 432/200000 [15:20<19:31:12,  2.84it/s, loss=0.433]<=============================== step 432  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 432/200000 [15:21<19:31:12,  2.84it/s, loss=0.433]stage 2: :   0%|          | 436/200000 [15:22<19:56:59,  2.78it/s, loss=0.433]stage 2: :   0%|          | 436/200000 [15:22<19:56:59,  2.78it/s, loss=0.387]<=============================== step 436  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.4680], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 436/200000 [15:22<19:56:59,  2.78it/s, loss=0.387]stage 2: :   0%|          | 440/200000 [15:23<20:14:11,  2.74it/s, loss=0.387]stage 2: :   0%|          | 440/200000 [15:23<20:14:11,  2.74it/s, loss=0.332]<=============================== step 440  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1170], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 440/200000 [15:24<20:14:11,  2.74it/s, loss=0.332]stage 2: :   0%|          | 444/200000 [15:25<20:38:43,  2.68it/s, loss=0.332]stage 2: :   0%|          | 444/200000 [15:25<20:38:43,  2.68it/s, loss=0.774]<=============================== step 444  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['horse']
controlnet: [True]
prompts: ['a photo of a bnha horse in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a horse']
stage 2: :   0%|          | 444/200000 [15:25<20:38:43,  2.68it/s, loss=0.774]stage 2: :   0%|          | 448/200000 [15:26<21:13:08,  2.61it/s, loss=0.774]stage 2: :   0%|          | 448/200000 [15:26<21:13:08,  2.61it/s, loss=0.502]<=============================== step 448  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1067], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 448/200000 [15:27<21:13:08,  2.61it/s, loss=0.502]stage 2: :   0%|          | 452/200000 [15:28<22:05:38,  2.51it/s, loss=0.502]stage 2: :   0%|          | 452/200000 [15:28<22:05:38,  2.51it/s, loss=0.483]<=============================== step 452  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 452/200000 [15:29<22:05:38,  2.51it/s, loss=0.483]stage 2: :   0%|          | 456/200000 [15:30<21:55:42,  2.53it/s, loss=0.483]stage 2: :   0%|          | 456/200000 [15:30<21:55:42,  2.53it/s, loss=0.487]<=============================== step 456  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus on a rocky cliff overlooking a vast ocean\n', 'a photo of a bus']
stage 2: :   0%|          | 456/200000 [15:30<21:55:42,  2.53it/s, loss=0.487]stage 2: :   0%|          | 460/200000 [15:31<21:46:00,  2.55it/s, loss=0.487]stage 2: :   0%|          | 460/200000 [15:31<21:46:00,  2.55it/s, loss=0.659]<=============================== step 460  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6981], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ['a photo of a bnha pickup truck in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a pickup truck']
stage 2: :   0%|          | 460/200000 [15:32<21:46:00,  2.55it/s, loss=0.659]stage 2: :   0%|          | 464/200000 [15:33<21:44:31,  2.55it/s, loss=0.659]stage 2: :   0%|          | 464/200000 [15:33<21:44:31,  2.55it/s, loss=0.462]<=============================== step 464  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 464/200000 [15:33<21:44:31,  2.55it/s, loss=0.462]stage 2: :   0%|          | 468/200000 [15:34<21:31:41,  2.57it/s, loss=0.462]stage 2: :   0%|          | 468/200000 [15:34<21:31:41,  2.57it/s, loss=0.349]<=============================== step 468  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3265], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 468/200000 [15:35<21:31:41,  2.57it/s, loss=0.349]stage 2: :   0%|          | 472/200000 [15:36<21:30:19,  2.58it/s, loss=0.349]stage 2: :   0%|          | 472/200000 [15:36<21:30:19,  2.58it/s, loss=0.513]<=============================== step 472  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.0698], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a motorbike']
stage 2: :   0%|          | 472/200000 [15:37<21:30:19,  2.58it/s, loss=0.513]stage 2: :   0%|          | 476/200000 [15:37<21:42:44,  2.55it/s, loss=0.513]stage 2: :   0%|          | 476/200000 [15:37<21:42:44,  2.55it/s, loss=0.66] <=============================== step 476  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0737], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a bus']
stage 2: :   0%|          | 476/200000 [15:38<21:42:44,  2.55it/s, loss=0.66]stage 2: :   0%|          | 480/200000 [15:39<21:45:43,  2.55it/s, loss=0.66]stage 2: :   0%|          | 480/200000 [15:39<21:45:43,  2.55it/s, loss=0.954]<=============================== step 480  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['horse']
controlnet: [True]
prompts: ['a photo of a bnha horse in a sunflower field under a clear blue sky\n', 'a photo of a horse']
stage 2: :   0%|          | 480/200000 [15:40<21:45:43,  2.55it/s, loss=0.954]stage 2: :   0%|          | 484/200000 [15:40<21:51:45,  2.53it/s, loss=0.954]stage 2: :   0%|          | 484/200000 [15:40<21:51:45,  2.53it/s, loss=0.624]<=============================== step 484  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2586], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 484/200000 [15:41<21:51:45,  2.53it/s, loss=0.624]stage 2: :   0%|          | 488/200000 [15:42<21:40:32,  2.56it/s, loss=0.624]stage 2: :   0%|          | 488/200000 [15:42<21:40:32,  2.56it/s, loss=0.367]<=============================== step 488  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7699], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 488/200000 [15:43<21:40:32,  2.56it/s, loss=0.367]stage 2: :   0%|          | 492/200000 [15:44<21:35:10,  2.57it/s, loss=0.367]stage 2: :   0%|          | 492/200000 [15:44<21:35:10,  2.57it/s, loss=0.533]<=============================== step 492  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant in a lush vineyard with rows of grapevines stretching into the distance\n', 'a photo of a elephant']
stage 2: :   0%|          | 492/200000 [15:44<21:35:10,  2.57it/s, loss=0.533]stage 2: :   0%|          | 496/200000 [15:45<21:54:52,  2.53it/s, loss=0.533]stage 2: :   0%|          | 496/200000 [15:45<21:54:52,  2.53it/s, loss=0.761]<=============================== step 496  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.6180], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 496/200000 [15:46<21:54:52,  2.53it/s, loss=0.761]stage 2: :   0%|          | 500/200000 [15:47<21:36:09,  2.57it/s, loss=0.761]/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Cross Attention is also updated!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Saving weights to ../ckpts/multiobject/__poseonly_subjectinprompt/lora_weight_500.safetensors
stage 2: :   0%|          | 500/200000 [15:48<21:36:09,  2.57it/s, loss=0.416]<=============================== step 500  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3633], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 500/200000 [15:49<21:36:09,  2.57it/s, loss=0.416]stage 2: :   0%|          | 504/200000 [15:50<28:16:06,  1.96it/s, loss=0.416]stage 2: :   0%|          | 504/200000 [15:50<28:16:06,  1.96it/s, loss=0.403]<=============================== step 504  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9095], device='cuda:0')
subjects: ['horse']
controlnet: [True]
prompts: ["a photo of a bnha horse at a river's edge with stones scattered around\n", 'a photo of a horse']
stage 2: :   0%|          | 504/200000 [15:51<28:16:06,  1.96it/s, loss=0.403]stage 2: :   0%|          | 508/200000 [15:51<26:09:09,  2.12it/s, loss=0.403]stage 2: :   0%|          | 508/200000 [15:51<26:09:09,  2.12it/s, loss=0.611]<=============================== step 508  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5851], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 508/200000 [15:52<26:09:09,  2.12it/s, loss=0.611]stage 2: :   0%|          | 512/200000 [15:53<24:27:22,  2.27it/s, loss=0.611]stage 2: :   0%|          | 512/200000 [15:53<24:27:22,  2.27it/s, loss=0.532]<=============================== step 512  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.8171], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike by a riverside with wildflowers blooming nearby\n', 'a photo of a motorbike']
stage 2: :   0%|          | 512/200000 [15:54<24:27:22,  2.27it/s, loss=0.532]stage 2: :   0%|          | 516/200000 [15:54<23:28:06,  2.36it/s, loss=0.532]stage 2: :   0%|          | 516/200000 [15:54<23:28:06,  2.36it/s, loss=0.582]<=============================== step 516  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4538], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 516/200000 [15:55<23:28:06,  2.36it/s, loss=0.582]stage 2: :   0%|          | 520/200000 [15:56<23:47:27,  2.33it/s, loss=0.582]stage 2: :   0%|          | 520/200000 [15:56<23:47:27,  2.33it/s, loss=0.464]<=============================== step 520  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.2483], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 520/200000 [15:57<23:47:27,  2.33it/s, loss=0.464]stage 2: :   0%|          | 524/200000 [15:58<23:06:05,  2.40it/s, loss=0.464]stage 2: :   0%|          | 524/200000 [15:58<23:06:05,  2.40it/s, loss=0.728]<=============================== step 524  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3840], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 524/200000 [15:58<23:06:05,  2.40it/s, loss=0.728]stage 2: :   0%|          | 528/200000 [15:59<22:30:40,  2.46it/s, loss=0.728]stage 2: :   0%|          | 528/200000 [15:59<22:30:40,  2.46it/s, loss=0.345]<=============================== step 528  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 528/200000 [16:00<22:30:40,  2.46it/s, loss=0.345]stage 2: :   0%|          | 532/200000 [16:01<22:32:57,  2.46it/s, loss=0.345]stage 2: :   0%|          | 532/200000 [16:01<22:32:57,  2.46it/s, loss=0.478]<=============================== step 532  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7822], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 532/200000 [16:02<22:32:57,  2.46it/s, loss=0.478]stage 2: :   0%|          | 536/200000 [16:02<22:13:09,  2.49it/s, loss=0.478]stage 2: :   0%|          | 536/200000 [16:02<22:13:09,  2.49it/s, loss=0.366]<=============================== step 536  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6981], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 536/200000 [16:03<22:13:09,  2.49it/s, loss=0.366]stage 2: :   0%|          | 540/200000 [16:04<21:48:35,  2.54it/s, loss=0.366]stage 2: :   0%|          | 540/200000 [16:04<21:48:35,  2.54it/s, loss=0.478]<=============================== step 540  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3387], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 540/200000 [16:05<21:48:35,  2.54it/s, loss=0.478]stage 2: :   0%|          | 544/200000 [16:05<21:26:17,  2.58it/s, loss=0.478]stage 2: :   0%|          | 544/200000 [16:05<21:26:17,  2.58it/s, loss=0.354]<=============================== step 544  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2340], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 544/200000 [16:06<21:26:17,  2.58it/s, loss=0.354]stage 2: :   0%|          | 548/200000 [16:07<21:13:00,  2.61it/s, loss=0.354]stage 2: :   0%|          | 548/200000 [16:07<21:13:00,  2.61it/s, loss=0.565]<=============================== step 548  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1868], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 548/200000 [16:08<21:13:00,  2.61it/s, loss=0.565]stage 2: :   0%|          | 552/200000 [16:08<21:01:31,  2.64it/s, loss=0.565]stage 2: :   0%|          | 552/200000 [16:08<21:01:31,  2.64it/s, loss=0.534]<=============================== step 552  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4538], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 552/200000 [16:09<21:01:31,  2.64it/s, loss=0.534]stage 2: :   0%|          | 556/200000 [16:10<20:56:37,  2.65it/s, loss=0.534]stage 2: :   0%|          | 556/200000 [16:10<20:56:37,  2.65it/s, loss=0.425]<=============================== step 556  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 556/200000 [16:11<20:56:37,  2.65it/s, loss=0.425]stage 2: :   0%|          | 560/200000 [16:11<20:50:26,  2.66it/s, loss=0.425]stage 2: :   0%|          | 560/200000 [16:11<20:50:26,  2.66it/s, loss=0.527]<=============================== step 560  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 560/200000 [16:12<20:50:26,  2.66it/s, loss=0.527]stage 2: :   0%|          | 564/200000 [16:13<20:59:33,  2.64it/s, loss=0.527]stage 2: :   0%|          | 564/200000 [16:13<20:59:33,  2.64it/s, loss=0.55] <=============================== step 564  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5152], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 564/200000 [16:14<20:59:33,  2.64it/s, loss=0.55]stage 2: :   0%|          | 568/200000 [16:14<20:48:33,  2.66it/s, loss=0.55]stage 2: :   0%|          | 568/200000 [16:14<20:48:33,  2.66it/s, loss=0.59]<=============================== step 568  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1662], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 568/200000 [16:15<20:48:33,  2.66it/s, loss=0.59]stage 2: :   0%|          | 572/200000 [16:16<20:44:50,  2.67it/s, loss=0.59]stage 2: :   0%|          | 572/200000 [16:16<20:44:50,  2.67it/s, loss=0.319]<=============================== step 572  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.2134], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 572/200000 [16:17<20:44:50,  2.67it/s, loss=0.319]stage 2: :   0%|          | 576/200000 [16:17<20:47:05,  2.67it/s, loss=0.319]stage 2: :   0%|          | 576/200000 [16:17<20:47:05,  2.67it/s, loss=0.471]<=============================== step 576  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7596], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 576/200000 [16:18<20:47:05,  2.67it/s, loss=0.471]stage 2: :   0%|          | 580/200000 [16:19<20:50:58,  2.66it/s, loss=0.471]stage 2: :   0%|          | 580/200000 [16:19<20:50:58,  2.66it/s, loss=0.444]<=============================== step 580  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7124], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 580/200000 [16:20<20:50:58,  2.66it/s, loss=0.444]stage 2: :   0%|          | 584/200000 [16:20<20:46:26,  2.67it/s, loss=0.444]stage 2: :   0%|          | 584/200000 [16:20<20:46:26,  2.67it/s, loss=0.435]<=============================== step 584  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7576], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 584/200000 [16:21<20:46:26,  2.67it/s, loss=0.435]stage 2: :   0%|          | 588/200000 [16:22<20:47:07,  2.66it/s, loss=0.435]stage 2: :   0%|          | 588/200000 [16:22<20:47:07,  2.66it/s, loss=0.563]<=============================== step 588  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8623], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 588/200000 [16:23<20:47:07,  2.66it/s, loss=0.563]stage 2: :   0%|          | 592/200000 [16:24<21:27:08,  2.58it/s, loss=0.563]stage 2: :   0%|          | 592/200000 [16:24<21:27:08,  2.58it/s, loss=0.424]<=============================== step 592  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.5236], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ["a photo of a bnha bus at a river's edge with stones scattered around\n", 'a photo of a bus']
stage 2: :   0%|          | 592/200000 [16:25<21:27:08,  2.58it/s, loss=0.424]stage 2: :   0%|          | 596/200000 [16:25<22:20:52,  2.48it/s, loss=0.424]stage 2: :   0%|          | 596/200000 [16:25<22:20:52,  2.48it/s, loss=0.65] <=============================== step 596  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 596/200000 [16:26<22:20:52,  2.48it/s, loss=0.65]stage 2: :   0%|          | 600/200000 [16:27<21:58:20,  2.52it/s, loss=0.65]stage 2: :   0%|          | 600/200000 [16:27<21:58:20,  2.52it/s, loss=0.522]<=============================== step 600  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0020], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 600/200000 [16:28<21:58:20,  2.52it/s, loss=0.522]stage 2: :   0%|          | 604/200000 [16:28<21:44:46,  2.55it/s, loss=0.522]stage 2: :   0%|          | 604/200000 [16:28<21:44:46,  2.55it/s, loss=0.595]<=============================== step 604  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.6549], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 604/200000 [16:29<21:44:46,  2.55it/s, loss=0.595]stage 2: :   0%|          | 608/200000 [16:30<21:39:16,  2.56it/s, loss=0.595]stage 2: :   0%|          | 608/200000 [16:30<21:39:16,  2.56it/s, loss=0.523]<=============================== step 608  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5831], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 608/200000 [16:31<21:39:16,  2.56it/s, loss=0.523]stage 2: :   0%|          | 612/200000 [16:31<21:26:28,  2.58it/s, loss=0.523]stage 2: :   0%|          | 612/200000 [16:31<21:26:28,  2.58it/s, loss=0.644]<=============================== step 612  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 612/200000 [16:32<21:26:28,  2.58it/s, loss=0.644]stage 2: :   0%|          | 616/200000 [16:33<21:27:07,  2.58it/s, loss=0.644]stage 2: :   0%|          | 616/200000 [16:33<21:27:07,  2.58it/s, loss=0.401]<=============================== step 616  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4435], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 616/200000 [16:34<21:27:07,  2.58it/s, loss=0.401]stage 2: :   0%|          | 620/200000 [16:35<21:15:27,  2.61it/s, loss=0.401]stage 2: :   0%|          | 620/200000 [16:35<21:15:27,  2.61it/s, loss=0.494]<=============================== step 620  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 620/200000 [16:35<21:15:27,  2.61it/s, loss=0.494]stage 2: :   0%|          | 624/200000 [16:36<21:08:20,  2.62it/s, loss=0.494]stage 2: :   0%|          | 624/200000 [16:36<21:08:20,  2.62it/s, loss=0.648]<=============================== step 624  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 624/200000 [16:37<21:08:20,  2.62it/s, loss=0.648]stage 2: :   0%|          | 628/200000 [16:38<21:06:14,  2.62it/s, loss=0.648]stage 2: :   0%|          | 628/200000 [16:38<21:06:14,  2.62it/s, loss=0.443]<=============================== step 628  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6283], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat on a rocky cliff overlooking a vast ocean\n', 'a photo of a cat']
stage 2: :   0%|          | 628/200000 [16:38<21:06:14,  2.62it/s, loss=0.443]stage 2: :   0%|          | 632/200000 [16:39<21:11:06,  2.61it/s, loss=0.443]stage 2: :   0%|          | 632/200000 [16:39<21:11:06,  2.61it/s, loss=0.559]<=============================== step 632  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9076], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 632/200000 [16:40<21:11:06,  2.61it/s, loss=0.559]stage 2: :   0%|          | 636/200000 [16:41<20:59:37,  2.64it/s, loss=0.559]stage 2: :   0%|          | 636/200000 [16:41<20:59:37,  2.64it/s, loss=0.398]<=============================== step 636  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 636/200000 [16:41<20:59:37,  2.64it/s, loss=0.398]stage 2: :   0%|          | 640/200000 [16:42<20:57:33,  2.64it/s, loss=0.398]stage 2: :   0%|          | 640/200000 [16:42<20:57:33,  2.64it/s, loss=0.456]<=============================== step 640  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5728], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 640/200000 [16:43<20:57:33,  2.64it/s, loss=0.456]stage 2: :   0%|          | 644/200000 [16:44<20:57:29,  2.64it/s, loss=0.456]stage 2: :   0%|          | 644/200000 [16:44<20:57:29,  2.64it/s, loss=0.577]<=============================== step 644  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8048], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 644/200000 [16:44<20:57:29,  2.64it/s, loss=0.577]stage 2: :   0%|          | 648/200000 [16:45<20:49:53,  2.66it/s, loss=0.577]stage 2: :   0%|          | 648/200000 [16:45<20:49:53,  2.66it/s, loss=0.43] <=============================== step 648  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3265], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 648/200000 [16:46<20:49:53,  2.66it/s, loss=0.43]stage 2: :   0%|          | 652/200000 [16:47<20:54:54,  2.65it/s, loss=0.43]stage 2: :   0%|          | 652/200000 [16:47<20:54:54,  2.65it/s, loss=0.525]<=============================== step 652  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.8171], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 652/200000 [16:47<20:54:54,  2.65it/s, loss=0.525]stage 2: :   0%|          | 656/200000 [16:48<20:50:31,  2.66it/s, loss=0.525]stage 2: :   0%|          | 656/200000 [16:48<20:50:31,  2.66it/s, loss=0.347]<=============================== step 656  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1519], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 656/200000 [16:49<20:50:31,  2.66it/s, loss=0.347]stage 2: :   0%|          | 660/200000 [16:50<20:54:18,  2.65it/s, loss=0.347]stage 2: :   0%|          | 660/200000 [16:50<20:54:18,  2.65it/s, loss=0.496]<=============================== step 660  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8992], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 660/200000 [16:50<20:54:18,  2.65it/s, loss=0.496]stage 2: :   0%|          | 664/200000 [16:51<21:17:18,  2.60it/s, loss=0.496]stage 2: :   0%|          | 664/200000 [16:51<21:17:18,  2.60it/s, loss=0.54] <=============================== step 664  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0944], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 664/200000 [16:52<21:17:18,  2.60it/s, loss=0.54]stage 2: :   0%|          | 668/200000 [16:53<21:07:43,  2.62it/s, loss=0.54]stage 2: :   0%|          | 668/200000 [16:53<21:07:43,  2.62it/s, loss=0.461]<=============================== step 668  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8746], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 668/200000 [16:53<21:07:43,  2.62it/s, loss=0.461]stage 2: :   0%|          | 672/200000 [16:54<21:00:57,  2.63it/s, loss=0.461]stage 2: :   0%|          | 672/200000 [16:54<21:00:57,  2.63it/s, loss=0.477]<=============================== step 672  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1745], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 672/200000 [16:55<21:00:57,  2.63it/s, loss=0.477]stage 2: :   0%|          | 676/200000 [16:56<21:50:51,  2.53it/s, loss=0.477]stage 2: :   0%|          | 676/200000 [16:56<21:50:51,  2.53it/s, loss=0.594]<=============================== step 676  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 676/200000 [16:57<21:50:51,  2.53it/s, loss=0.594]stage 2: :   0%|          | 680/200000 [16:57<21:41:43,  2.55it/s, loss=0.594]stage 2: :   0%|          | 680/200000 [16:57<21:41:43,  2.55it/s, loss=0.644]<=============================== step 680  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0388], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 680/200000 [16:58<21:41:43,  2.55it/s, loss=0.644]stage 2: :   0%|          | 684/200000 [16:59<21:20:07,  2.59it/s, loss=0.644]stage 2: :   0%|          | 684/200000 [16:59<21:20:07,  2.59it/s, loss=0.439]<=============================== step 684  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2114], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 684/200000 [17:00<21:20:07,  2.59it/s, loss=0.439]stage 2: :   0%|          | 688/200000 [17:00<21:13:12,  2.61it/s, loss=0.439]stage 2: :   0%|          | 688/200000 [17:00<21:13:12,  2.61it/s, loss=0.371]<=============================== step 688  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5359], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant in a sunflower field under a clear blue sky\n', 'a photo of a elephant']
stage 2: :   0%|          | 688/200000 [17:01<21:13:12,  2.61it/s, loss=0.371]stage 2: :   0%|          | 692/200000 [17:02<21:14:45,  2.61it/s, loss=0.371]stage 2: :   0%|          | 692/200000 [17:02<21:14:45,  2.61it/s, loss=0.733]<=============================== step 692  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2586], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 692/200000 [17:03<21:14:45,  2.61it/s, loss=0.733]stage 2: :   0%|          | 696/200000 [17:04<21:13:08,  2.61it/s, loss=0.733]stage 2: :   0%|          | 696/200000 [17:04<21:13:08,  2.61it/s, loss=0.611]<=============================== step 696  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8643], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 696/200000 [17:04<21:13:08,  2.61it/s, loss=0.611]stage 2: :   0%|          | 700/200000 [17:05<21:18:14,  2.60it/s, loss=0.611]stage 2: :   0%|          | 700/200000 [17:05<21:18:14,  2.60it/s, loss=0.363]<=============================== step 700  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8643], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant in a sunflower field under a clear blue sky\n', 'a photo of a elephant']
stage 2: :   0%|          | 700/200000 [17:06<21:18:14,  2.60it/s, loss=0.363]stage 2: :   0%|          | 704/200000 [17:07<21:42:26,  2.55it/s, loss=0.363]stage 2: :   0%|          | 704/200000 [17:07<21:42:26,  2.55it/s, loss=0.601]<=============================== step 704  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.2483], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 704/200000 [17:07<21:42:26,  2.55it/s, loss=0.601]stage 2: :   0%|          | 708/200000 [17:08<21:29:17,  2.58it/s, loss=0.601]stage 2: :   0%|          | 708/200000 [17:08<21:29:17,  2.58it/s, loss=0.469]<=============================== step 708  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1170], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 708/200000 [17:09<21:29:17,  2.58it/s, loss=0.469]stage 2: :   0%|          | 712/200000 [17:10<21:31:29,  2.57it/s, loss=0.469]stage 2: :   0%|          | 712/200000 [17:10<21:31:29,  2.57it/s, loss=0.448]<=============================== step 712  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1047], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 712/200000 [17:11<21:31:29,  2.57it/s, loss=0.448]stage 2: :   0%|          | 716/200000 [17:11<21:29:12,  2.58it/s, loss=0.448]stage 2: :   0%|          | 716/200000 [17:11<21:29:12,  2.58it/s, loss=0.557]<=============================== step 716  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a lion']
stage 2: :   0%|          | 716/200000 [17:12<21:29:12,  2.58it/s, loss=0.557]stage 2: :   0%|          | 720/200000 [17:13<21:31:27,  2.57it/s, loss=0.557]stage 2: :   0%|          | 720/200000 [17:13<21:31:27,  2.57it/s, loss=0.676]<=============================== step 720  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2793], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 720/200000 [17:14<21:31:27,  2.57it/s, loss=0.676]stage 2: :   0%|          | 724/200000 [17:14<21:18:49,  2.60it/s, loss=0.676]stage 2: :   0%|          | 724/200000 [17:14<21:18:49,  2.60it/s, loss=0.346]<=============================== step 724  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3038], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 724/200000 [17:15<21:18:49,  2.60it/s, loss=0.346]stage 2: :   0%|          | 728/200000 [17:16<21:09:10,  2.62it/s, loss=0.346]stage 2: :   0%|          | 728/200000 [17:16<21:09:10,  2.62it/s, loss=0.541]<=============================== step 728  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0143], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 728/200000 [17:17<21:09:10,  2.62it/s, loss=0.541]stage 2: :   0%|          | 732/200000 [17:17<21:01:41,  2.63it/s, loss=0.541]stage 2: :   0%|          | 732/200000 [17:17<21:01:41,  2.63it/s, loss=0.409]<=============================== step 732  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2443], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 732/200000 [17:18<21:01:41,  2.63it/s, loss=0.409]stage 2: :   0%|          | 736/200000 [17:19<21:04:15,  2.63it/s, loss=0.409]stage 2: :   0%|          | 736/200000 [17:19<21:04:15,  2.63it/s, loss=0.511]<=============================== step 736  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5831], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 736/200000 [17:20<21:04:15,  2.63it/s, loss=0.511]stage 2: :   0%|          | 740/200000 [17:21<21:15:42,  2.60it/s, loss=0.511]stage 2: :   0%|          | 740/200000 [17:21<21:15:42,  2.60it/s, loss=0.437]<=============================== step 740  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6632], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 740/200000 [17:21<21:15:42,  2.60it/s, loss=0.437]stage 2: :   0%|          | 744/200000 [17:22<21:04:13,  2.63it/s, loss=0.437]stage 2: :   0%|          | 744/200000 [17:22<21:04:13,  2.63it/s, loss=0.545]<=============================== step 744  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1745], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 744/200000 [17:23<21:04:13,  2.63it/s, loss=0.545]stage 2: :   0%|          | 748/200000 [17:24<21:00:20,  2.63it/s, loss=0.545]stage 2: :   0%|          | 748/200000 [17:24<21:00:20,  2.63it/s, loss=0.449]<=============================== step 748  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7227], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in space with the Milky Way galaxy stretching across the background ', 'a photo of a bus']
stage 2: :   0%|          | 748/200000 [17:24<21:00:20,  2.63it/s, loss=0.449]stage 2: :   0%|          | 752/200000 [17:25<21:14:58,  2.60it/s, loss=0.449]stage 2: :   0%|          | 752/200000 [17:25<21:14:58,  2.60it/s, loss=0.567]<=============================== step 752  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8378], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a jeep']
stage 2: :   0%|          | 752/200000 [17:26<21:14:58,  2.60it/s, loss=0.567]stage 2: :   0%|          | 756/200000 [17:27<22:14:08,  2.49it/s, loss=0.567]stage 2: :   0%|          | 756/200000 [17:27<22:14:08,  2.49it/s, loss=0.607]<=============================== step 756  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 756/200000 [17:28<22:14:08,  2.49it/s, loss=0.607]stage 2: :   0%|          | 760/200000 [17:28<21:46:33,  2.54it/s, loss=0.607]stage 2: :   0%|          | 760/200000 [17:28<21:46:33,  2.54it/s, loss=0.442]<=============================== step 760  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8029], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 760/200000 [17:29<21:46:33,  2.54it/s, loss=0.442]stage 2: :   0%|          | 764/200000 [17:30<21:27:30,  2.58it/s, loss=0.442]stage 2: :   0%|          | 764/200000 [17:30<21:27:30,  2.58it/s, loss=0.585]<=============================== step 764  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1436], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 764/200000 [17:31<21:27:30,  2.58it/s, loss=0.585]stage 2: :   0%|          | 768/200000 [17:31<21:15:44,  2.60it/s, loss=0.585]stage 2: :   0%|          | 768/200000 [17:31<21:15:44,  2.60it/s, loss=0.411]<=============================== step 768  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5152], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in a sunflower field under a clear blue sky\n', 'a photo of a jeep']
stage 2: :   0%|          | 768/200000 [17:32<21:15:44,  2.60it/s, loss=0.411]stage 2: :   0%|          | 772/200000 [17:33<21:25:21,  2.58it/s, loss=0.411]stage 2: :   0%|          | 772/200000 [17:33<21:25:21,  2.58it/s, loss=0.572]<=============================== step 772  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8397], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 772/200000 [17:34<21:25:21,  2.58it/s, loss=0.572]stage 2: :   0%|          | 776/200000 [17:34<21:16:42,  2.60it/s, loss=0.572]stage 2: :   0%|          | 776/200000 [17:34<21:16:42,  2.60it/s, loss=0.506]<=============================== step 776  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2217], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ['a photo of a bnha pickup truck on a riverbank at sunrise, with mist rising from the water\n', 'a photo of a pickup truck']
stage 2: :   0%|          | 776/200000 [17:35<21:16:42,  2.60it/s, loss=0.506]stage 2: :   0%|          | 780/200000 [17:36<21:14:45,  2.60it/s, loss=0.506]stage 2: :   0%|          | 780/200000 [17:36<21:14:45,  2.60it/s, loss=0.726]<=============================== step 780  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0841], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 780/200000 [17:37<21:14:45,  2.60it/s, loss=0.726]stage 2: :   0%|          | 784/200000 [17:37<21:12:33,  2.61it/s, loss=0.726]stage 2: :   0%|          | 784/200000 [17:38<21:12:33,  2.61it/s, loss=0.508]<=============================== step 784  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6632], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 784/200000 [17:38<21:12:33,  2.61it/s, loss=0.508]stage 2: :   0%|          | 788/200000 [17:39<21:04:00,  2.63it/s, loss=0.508]stage 2: :   0%|          | 788/200000 [17:39<21:04:00,  2.63it/s, loss=0.409]<=============================== step 788  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2566], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 788/200000 [17:40<21:04:00,  2.63it/s, loss=0.409]stage 2: :   0%|          | 792/200000 [17:41<21:03:59,  2.63it/s, loss=0.409]stage 2: :   0%|          | 792/200000 [17:41<21:03:59,  2.63it/s, loss=0.71] <=============================== step 792  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4454], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 792/200000 [17:41<21:03:59,  2.63it/s, loss=0.71]stage 2: :   0%|          | 796/200000 [17:42<20:57:53,  2.64it/s, loss=0.71]stage 2: :   0%|          | 796/200000 [17:42<20:57:53,  2.64it/s, loss=0.333]<=============================== step 796  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 796/200000 [17:43<20:57:53,  2.64it/s, loss=0.333]stage 2: :   0%|          | 800/200000 [17:44<20:56:23,  2.64it/s, loss=0.333]stage 2: :   0%|          | 800/200000 [17:44<20:56:23,  2.64it/s, loss=0.37] <=============================== step 800  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7802], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 800/200000 [17:44<20:56:23,  2.64it/s, loss=0.37]stage 2: :   0%|          | 804/200000 [17:45<20:50:37,  2.65it/s, loss=0.37]stage 2: :   0%|          | 804/200000 [17:45<20:50:37,  2.65it/s, loss=0.422]<=============================== step 804  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9548], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 804/200000 [17:46<20:50:37,  2.65it/s, loss=0.422]stage 2: :   0%|          | 808/200000 [17:47<20:46:55,  2.66it/s, loss=0.422]stage 2: :   0%|          | 808/200000 [17:47<20:46:55,  2.66it/s, loss=0.438]<=============================== step 808  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 808/200000 [17:47<20:46:55,  2.66it/s, loss=0.438]stage 2: :   0%|          | 812/200000 [17:48<20:50:03,  2.66it/s, loss=0.438]stage 2: :   0%|          | 812/200000 [17:48<20:50:03,  2.66it/s, loss=0.396]<=============================== step 812  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.6406], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus by a riverside with wildflowers blooming nearby\n', 'a photo of a bus']
stage 2: :   0%|          | 812/200000 [17:49<20:50:03,  2.66it/s, loss=0.396]stage 2: :   0%|          | 816/200000 [17:50<20:58:05,  2.64it/s, loss=0.396]stage 2: :   0%|          | 816/200000 [17:50<20:58:05,  2.64it/s, loss=0.858]<=============================== step 816  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.6652], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 816/200000 [17:50<20:58:05,  2.64it/s, loss=0.858]stage 2: :   0%|          | 820/200000 [17:51<20:50:52,  2.65it/s, loss=0.858]stage 2: :   0%|          | 820/200000 [17:51<20:50:52,  2.65it/s, loss=0.563]<=============================== step 820  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3963], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 820/200000 [17:52<20:50:52,  2.65it/s, loss=0.563]stage 2: :   0%|          | 824/200000 [17:53<20:51:05,  2.65it/s, loss=0.563]stage 2: :   0%|          | 824/200000 [17:53<20:51:05,  2.65it/s, loss=0.377]<=============================== step 824  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4907], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in front of the Eiffel Tower at night, with the tower illuminated by lights\n', 'a photo of a jeep']
stage 2: :   0%|          | 824/200000 [17:53<20:51:05,  2.65it/s, loss=0.377]stage 2: :   0%|          | 828/200000 [17:54<21:06:02,  2.62it/s, loss=0.377]stage 2: :   0%|          | 828/200000 [17:54<21:06:02,  2.62it/s, loss=0.59] <=============================== step 828  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7576], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 828/200000 [17:55<21:06:02,  2.62it/s, loss=0.59]stage 2: :   0%|          | 832/200000 [17:56<21:47:20,  2.54it/s, loss=0.59]stage 2: :   0%|          | 832/200000 [17:56<21:47:20,  2.54it/s, loss=0.407]<=============================== step 832  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 832/200000 [17:57<21:47:20,  2.54it/s, loss=0.407]stage 2: :   0%|          | 836/200000 [17:57<21:32:18,  2.57it/s, loss=0.407]stage 2: :   0%|          | 836/200000 [17:57<21:32:18,  2.57it/s, loss=0.503]<=============================== step 836  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.7330], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 836/200000 [17:58<21:32:18,  2.57it/s, loss=0.503]stage 2: :   0%|          | 840/200000 [17:59<21:20:28,  2.59it/s, loss=0.503]stage 2: :   0%|          | 840/200000 [17:59<21:20:28,  2.59it/s, loss=0.411]<=============================== step 840  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 840/200000 [18:00<21:20:28,  2.59it/s, loss=0.411]stage 2: :   0%|          | 844/200000 [18:00<21:09:09,  2.62it/s, loss=0.411]stage 2: :   0%|          | 844/200000 [18:00<21:09:09,  2.62it/s, loss=0.404]<=============================== step 844  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2360], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 844/200000 [18:01<21:09:09,  2.62it/s, loss=0.404]stage 2: :   0%|          | 848/200000 [18:02<21:05:04,  2.62it/s, loss=0.404]stage 2: :   0%|          | 848/200000 [18:02<21:05:04,  2.62it/s, loss=0.57] <=============================== step 848  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.1642], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 848/200000 [18:03<21:05:04,  2.62it/s, loss=0.57]stage 2: :   0%|          | 852/200000 [18:03<20:52:24,  2.65it/s, loss=0.57]stage 2: :   0%|          | 852/200000 [18:03<20:52:24,  2.65it/s, loss=0.428]<=============================== step 852  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6632], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 852/200000 [18:04<20:52:24,  2.65it/s, loss=0.428]stage 2: :   0%|          | 856/200000 [18:05<20:51:59,  2.65it/s, loss=0.428]stage 2: :   0%|          | 856/200000 [18:05<20:51:59,  2.65it/s, loss=0.547]<=============================== step 856  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.0698], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a elephant']
stage 2: :   0%|          | 856/200000 [18:06<20:51:59,  2.65it/s, loss=0.547]stage 2: :   0%|          | 860/200000 [18:06<20:59:30,  2.64it/s, loss=0.547]stage 2: :   0%|          | 860/200000 [18:06<20:59:30,  2.64it/s, loss=0.516]<=============================== step 860  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5708], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in a sunflower field under a clear blue sky\n', 'a photo of a bus']
stage 2: :   0%|          | 860/200000 [18:07<20:59:30,  2.64it/s, loss=0.516]stage 2: :   0%|          | 864/200000 [18:08<21:05:02,  2.62it/s, loss=0.516]stage 2: :   0%|          | 864/200000 [18:08<21:05:02,  2.62it/s, loss=0.617]<=============================== step 864  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9425], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 864/200000 [18:09<21:05:02,  2.62it/s, loss=0.617]stage 2: :   0%|          | 868/200000 [18:09<20:59:31,  2.64it/s, loss=0.617]stage 2: :   0%|          | 868/200000 [18:09<20:59:31,  2.64it/s, loss=0.436]<=============================== step 868  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1087], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 868/200000 [18:10<20:59:31,  2.64it/s, loss=0.436]stage 2: :   0%|          | 872/200000 [18:11<20:54:11,  2.65it/s, loss=0.436]stage 2: :   0%|          | 872/200000 [18:11<20:54:11,  2.65it/s, loss=0.437]<=============================== step 872  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0841], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 872/200000 [18:12<20:54:11,  2.65it/s, loss=0.437]stage 2: :   0%|          | 876/200000 [18:12<20:53:13,  2.65it/s, loss=0.437]stage 2: :   0%|          | 876/200000 [18:12<20:53:13,  2.65it/s, loss=0.579]<=============================== step 876  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6426], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 876/200000 [18:13<20:53:13,  2.65it/s, loss=0.579]stage 2: :   0%|          | 880/200000 [18:14<20:53:12,  2.65it/s, loss=0.579]stage 2: :   0%|          | 880/200000 [18:14<20:53:12,  2.65it/s, loss=0.62] <=============================== step 880  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5133], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a cat']
stage 2: :   0%|          | 880/200000 [18:15<20:53:12,  2.65it/s, loss=0.62]stage 2: :   0%|          | 884/200000 [18:16<21:17:31,  2.60it/s, loss=0.62]stage 2: :   0%|          | 884/200000 [18:16<21:17:31,  2.60it/s, loss=0.522]<=============================== step 884  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2586], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 884/200000 [18:16<21:17:31,  2.60it/s, loss=0.522]stage 2: :   0%|          | 888/200000 [18:17<21:21:37,  2.59it/s, loss=0.522]stage 2: :   0%|          | 888/200000 [18:17<21:21:37,  2.59it/s, loss=0.446]<=============================== step 888  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1868], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 888/200000 [18:18<21:21:37,  2.59it/s, loss=0.446]stage 2: :   0%|          | 892/200000 [18:19<21:18:29,  2.60it/s, loss=0.446]stage 2: :   0%|          | 892/200000 [18:19<21:18:29,  2.60it/s, loss=0.513]<=============================== step 892  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5954], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 892/200000 [18:19<21:18:29,  2.60it/s, loss=0.513]stage 2: :   0%|          | 896/200000 [18:20<21:15:39,  2.60it/s, loss=0.513]stage 2: :   0%|          | 896/200000 [18:20<21:15:39,  2.60it/s, loss=0.512]<=============================== step 896  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7001], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 896/200000 [18:21<21:15:39,  2.60it/s, loss=0.512]stage 2: :   0%|          | 900/200000 [18:22<21:17:13,  2.60it/s, loss=0.512]stage 2: :   0%|          | 900/200000 [18:22<21:17:13,  2.60it/s, loss=0.491]<=============================== step 900  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0143], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 900/200000 [18:23<21:17:13,  2.60it/s, loss=0.491]stage 2: :   0%|          | 904/200000 [18:23<21:28:18,  2.58it/s, loss=0.491]stage 2: :   0%|          | 904/200000 [18:23<21:28:18,  2.58it/s, loss=0.507]<=============================== step 904  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2094], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a sunflower field under a clear blue sky\n', 'a photo of a cat']
stage 2: :   0%|          | 904/200000 [18:24<21:28:18,  2.58it/s, loss=0.507]stage 2: :   0%|          | 908/200000 [18:25<21:25:22,  2.58it/s, loss=0.507]stage 2: :   0%|          | 908/200000 [18:25<21:25:22,  2.58it/s, loss=0.733]<=============================== step 908  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5010], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 908/200000 [18:26<21:25:22,  2.58it/s, loss=0.733]stage 2: :   0%|          | 912/200000 [18:27<22:11:29,  2.49it/s, loss=0.733]stage 2: :   0%|          | 912/200000 [18:27<22:11:29,  2.49it/s, loss=0.352]<=============================== step 912  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 912/200000 [18:27<22:11:29,  2.49it/s, loss=0.352]stage 2: :   0%|          | 916/200000 [18:28<21:51:07,  2.53it/s, loss=0.352]stage 2: :   0%|          | 916/200000 [18:28<21:51:07,  2.53it/s, loss=0.519]<=============================== step 916  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1087], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a dense rainforest, with sunlight streaming through the canopy\n', 'a photo of a lion']
stage 2: :   0%|          | 916/200000 [18:29<21:51:07,  2.53it/s, loss=0.519]stage 2: :   0%|          | 920/200000 [18:30<22:01:04,  2.51it/s, loss=0.519]stage 2: :   0%|          | 920/200000 [18:30<22:01:04,  2.51it/s, loss=0.512]<=============================== step 920  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.6529], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a bus']
stage 2: :   0%|          | 920/200000 [18:31<22:01:04,  2.51it/s, loss=0.512]stage 2: :   0%|          | 924/200000 [18:31<22:10:47,  2.49it/s, loss=0.512]stage 2: :   0%|          | 924/200000 [18:31<22:10:47,  2.49it/s, loss=0.549]<=============================== step 924  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.1888], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 924/200000 [18:32<22:10:47,  2.49it/s, loss=0.549]stage 2: :   0%|          | 928/200000 [18:33<22:22:23,  2.47it/s, loss=0.549]stage 2: :   0%|          | 928/200000 [18:33<22:22:23,  2.47it/s, loss=0.419]<=============================== step 928  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.6878], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 928/200000 [18:34<22:22:23,  2.47it/s, loss=0.419]stage 2: :   0%|          | 932/200000 [18:34<21:53:29,  2.53it/s, loss=0.419]stage 2: :   0%|          | 932/200000 [18:34<21:53:29,  2.53it/s, loss=0.451]<=============================== step 932  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 932/200000 [18:35<21:53:29,  2.53it/s, loss=0.451]stage 2: :   0%|          | 936/200000 [18:36<21:28:19,  2.58it/s, loss=0.451]stage 2: :   0%|          | 936/200000 [18:36<21:28:19,  2.58it/s, loss=0.614]<=============================== step 936  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.0964], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 936/200000 [18:37<21:28:19,  2.58it/s, loss=0.614]stage 2: :   0%|          | 940/200000 [18:37<21:12:18,  2.61it/s, loss=0.614]stage 2: :   0%|          | 940/200000 [18:37<21:12:18,  2.61it/s, loss=0.497]<=============================== step 940  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5133], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 940/200000 [18:38<21:12:18,  2.61it/s, loss=0.497]stage 2: :   0%|          | 944/200000 [18:39<21:03:04,  2.63it/s, loss=0.497]stage 2: :   0%|          | 944/200000 [18:39<21:03:04,  2.63it/s, loss=0.481]<=============================== step 944  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 944/200000 [18:40<21:03:04,  2.63it/s, loss=0.481]stage 2: :   0%|          | 948/200000 [18:41<21:07:22,  2.62it/s, loss=0.481]stage 2: :   0%|          | 948/200000 [18:41<21:07:22,  2.62it/s, loss=0.481]<=============================== step 948  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2237], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a dense rainforest, with sunlight streaming through the canopy\n', 'a photo of a cat']
stage 2: :   0%|          | 948/200000 [18:41<21:07:22,  2.62it/s, loss=0.481]stage 2: :   0%|          | 952/200000 [18:42<21:05:28,  2.62it/s, loss=0.481]stage 2: :   0%|          | 952/200000 [18:42<21:05:28,  2.62it/s, loss=0.549]<=============================== step 952  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 952/200000 [18:43<21:05:28,  2.62it/s, loss=0.549]stage 2: :   0%|          | 956/200000 [18:44<20:58:57,  2.64it/s, loss=0.549]stage 2: :   0%|          | 956/200000 [18:44<20:58:57,  2.64it/s, loss=0.538]<=============================== step 956  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5029], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant by a riverside with wildflowers blooming nearby\n', 'a photo of a elephant']
stage 2: :   0%|          | 956/200000 [18:44<20:58:57,  2.64it/s, loss=0.538]stage 2: :   0%|          | 960/200000 [18:45<20:59:04,  2.63it/s, loss=0.538]stage 2: :   0%|          | 960/200000 [18:45<20:59:04,  2.63it/s, loss=0.576]<=============================== step 960  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5256], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant by a riverside with wildflowers blooming nearby\n', 'a photo of a elephant']
stage 2: :   0%|          | 960/200000 [18:46<20:59:04,  2.63it/s, loss=0.576]stage 2: :   0%|          | 964/200000 [18:47<21:03:22,  2.63it/s, loss=0.576]stage 2: :   0%|          | 964/200000 [18:47<21:03:22,  2.63it/s, loss=0.503]<=============================== step 964  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6077], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 964/200000 [18:47<21:03:22,  2.63it/s, loss=0.503]stage 2: :   0%|          | 968/200000 [18:48<21:04:13,  2.62it/s, loss=0.503]stage 2: :   0%|          | 968/200000 [18:48<21:04:13,  2.62it/s, loss=0.596]<=============================== step 968  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.6652], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 968/200000 [18:49<21:04:13,  2.62it/s, loss=0.596]stage 2: :   0%|          | 972/200000 [18:50<21:09:27,  2.61it/s, loss=0.596]stage 2: :   0%|          | 972/200000 [18:50<21:09:27,  2.61it/s, loss=0.574]<=============================== step 972  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3265], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 972/200000 [18:50<21:09:27,  2.61it/s, loss=0.574]stage 2: :   0%|          | 976/200000 [18:51<21:14:23,  2.60it/s, loss=0.574]stage 2: :   0%|          | 976/200000 [18:51<21:14:23,  2.60it/s, loss=0.504]<=============================== step 976  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7453], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a lion']
stage 2: :   0%|          | 976/200000 [18:52<21:14:23,  2.60it/s, loss=0.504]stage 2: :   0%|          | 980/200000 [18:53<21:22:36,  2.59it/s, loss=0.504]stage 2: :   0%|          | 980/200000 [18:53<21:22:36,  2.59it/s, loss=0.497]<=============================== step 980  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7945], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 980/200000 [18:54<21:22:36,  2.59it/s, loss=0.497]stage 2: :   0%|          | 984/200000 [18:54<21:23:02,  2.59it/s, loss=0.497]stage 2: :   0%|          | 984/200000 [18:54<21:23:02,  2.59it/s, loss=0.619]<=============================== step 984  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7473], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in space with the Milky Way galaxy stretching across the background ', 'a photo of a jeep']
stage 2: :   0%|          | 984/200000 [18:55<21:23:02,  2.59it/s, loss=0.619]stage 2: :   0%|          | 988/200000 [18:56<21:23:11,  2.58it/s, loss=0.619]stage 2: :   0%|          | 988/200000 [18:56<21:23:11,  2.58it/s, loss=0.65] <=============================== step 988  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7945], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 988/200000 [18:57<21:23:11,  2.58it/s, loss=0.65]stage 2: :   0%|          | 992/200000 [18:58<21:54:43,  2.52it/s, loss=0.65]stage 2: :   0%|          | 992/200000 [18:58<21:54:43,  2.52it/s, loss=0.52]<=============================== step 992  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7945], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 992/200000 [18:58<21:54:43,  2.52it/s, loss=0.52]stage 2: :   0%|          | 996/200000 [18:59<21:33:54,  2.56it/s, loss=0.52]stage 2: :   0%|          | 996/200000 [18:59<21:33:54,  2.56it/s, loss=0.379]<=============================== step 996  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 996/200000 [19:00<21:33:54,  2.56it/s, loss=0.379]stage 2: :   0%|          | 1000/200000 [19:01<21:25:00,  2.58it/s, loss=0.379]/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Cross Attention is also updated!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Saving weights to ../ckpts/multiobject/__poseonly_subjectinprompt/lora_weight_1000.safetensors
stage 2: :   0%|          | 1000/200000 [19:02<21:25:00,  2.58it/s, loss=0.402]<=============================== step 1000  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1765], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 1000/200000 [19:03<21:25:00,  2.58it/s, loss=0.402]stage 2: :   1%|          | 1004/200000 [19:04<27:10:22,  2.03it/s, loss=0.402]stage 2: :   1%|          | 1004/200000 [19:04<27:10:22,  2.03it/s, loss=0.62] <=============================== step 1004  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8294], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1004/200000 [19:04<27:10:22,  2.03it/s, loss=0.62]stage 2: :   1%|          | 1008/200000 [19:05<25:12:10,  2.19it/s, loss=0.62]stage 2: :   1%|          | 1008/200000 [19:05<25:12:10,  2.19it/s, loss=0.557]<=============================== step 1008  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.8171], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1008/200000 [19:06<25:12:10,  2.19it/s, loss=0.557]stage 2: :   1%|          | 1012/200000 [19:07<23:52:21,  2.32it/s, loss=0.557]stage 2: :   1%|          | 1012/200000 [19:07<23:52:21,  2.32it/s, loss=0.8]  <=============================== step 1012  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3736], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1012/200000 [19:07<23:52:21,  2.32it/s, loss=0.8]stage 2: :   1%|          | 1016/200000 [19:08<23:00:22,  2.40it/s, loss=0.8]stage 2: :   1%|          | 1016/200000 [19:08<23:00:22,  2.40it/s, loss=0.389]<=============================== step 1016  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2340], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1016/200000 [19:09<23:00:22,  2.40it/s, loss=0.389]stage 2: :   1%|          | 1020/200000 [19:10<22:15:35,  2.48it/s, loss=0.389]stage 2: :   1%|          | 1020/200000 [19:10<22:15:35,  2.48it/s, loss=0.513]<=============================== step 1020  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.9322], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1020/200000 [19:10<22:15:35,  2.48it/s, loss=0.513]stage 2: :   1%|          | 1024/200000 [19:11<21:48:09,  2.54it/s, loss=0.513]stage 2: :   1%|          | 1024/200000 [19:11<21:48:09,  2.54it/s, loss=0.455]<=============================== step 1024  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2709], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1024/200000 [19:12<21:48:09,  2.54it/s, loss=0.455]stage 2: :   1%|          | 1028/200000 [19:12<21:20:22,  2.59it/s, loss=0.455]stage 2: :   1%|          | 1028/200000 [19:12<21:20:22,  2.59it/s, loss=0.518]<=============================== step 1028  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9794], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in space with the Milky Way galaxy stretching across the background ', 'a photo of a lion']
stage 2: :   1%|          | 1028/200000 [19:13<21:20:22,  2.59it/s, loss=0.518]stage 2: :   1%|          | 1032/200000 [19:14<21:27:00,  2.58it/s, loss=0.518]stage 2: :   1%|          | 1032/200000 [19:14<21:27:00,  2.58it/s, loss=0.491]<=============================== step 1032  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9341], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1032/200000 [19:15<21:27:00,  2.58it/s, loss=0.491]stage 2: :   1%|          | 1036/200000 [19:16<21:20:13,  2.59it/s, loss=0.491]stage 2: :   1%|          | 1036/200000 [19:16<21:20:13,  2.59it/s, loss=0.388]<=============================== step 1036  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5359], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a cat']
stage 2: :   1%|          | 1036/200000 [19:16<21:20:13,  2.59it/s, loss=0.388]stage 2: :   1%|          | 1040/200000 [19:17<21:16:52,  2.60it/s, loss=0.388]stage 2: :   1%|          | 1040/200000 [19:17<21:16:52,  2.60it/s, loss=0.591]<=============================== step 1040  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.1190], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1040/200000 [19:18<21:16:52,  2.60it/s, loss=0.591]stage 2: :   1%|          | 1044/200000 [19:19<21:08:42,  2.61it/s, loss=0.591]stage 2: :   1%|          | 1044/200000 [19:19<21:08:42,  2.61it/s, loss=0.484]<=============================== step 1044  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1044/200000 [19:19<21:08:42,  2.61it/s, loss=0.484]stage 2: :   1%|          | 1048/200000 [19:20<21:10:48,  2.61it/s, loss=0.484]stage 2: :   1%|          | 1048/200000 [19:20<21:10:48,  2.61it/s, loss=0.465]<=============================== step 1048  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2217], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1048/200000 [19:21<21:10:48,  2.61it/s, loss=0.465]stage 2: :   1%|          | 1052/200000 [19:22<21:59:26,  2.51it/s, loss=0.465]stage 2: :   1%|          | 1052/200000 [19:22<21:59:26,  2.51it/s, loss=0.523]<=============================== step 1052  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1052/200000 [19:23<21:59:26,  2.51it/s, loss=0.523]stage 2: :   1%|          | 1056/200000 [19:23<21:23:17,  2.58it/s, loss=0.523]stage 2: :   1%|          | 1056/200000 [19:23<21:23:17,  2.58it/s, loss=0.429]<=============================== step 1056  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5851], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1056/200000 [19:24<21:23:17,  2.58it/s, loss=0.429]stage 2: :   1%|          | 1060/200000 [19:25<20:32:24,  2.69it/s, loss=0.429]stage 2: :   1%|          | 1060/200000 [19:25<20:32:24,  2.69it/s, loss=0.351]<=============================== step 1060  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3284], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1060/200000 [19:25<20:32:24,  2.69it/s, loss=0.351]stage 2: :   1%|          | 1064/200000 [19:26<20:21:39,  2.71it/s, loss=0.351]stage 2: :   1%|          | 1064/200000 [19:26<20:21:39,  2.71it/s, loss=0.477]<=============================== step 1064  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2689], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1064/200000 [19:27<20:21:39,  2.71it/s, loss=0.477]stage 2: :   1%|          | 1068/200000 [19:27<19:38:49,  2.81it/s, loss=0.477]stage 2: :   1%|          | 1068/200000 [19:27<19:38:49,  2.81it/s, loss=0.4]  <=============================== step 1068  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2114], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1068/200000 [19:28<19:38:49,  2.81it/s, loss=0.4]stage 2: :   1%|          | 1072/200000 [19:29<19:12:36,  2.88it/s, loss=0.4]stage 2: :   1%|          | 1072/200000 [19:29<19:12:36,  2.88it/s, loss=0.505]<=============================== step 1072  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1662], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in front of the Eiffel Tower at night, with the tower illuminated by lights\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1072/200000 [19:29<19:12:36,  2.88it/s, loss=0.505]stage 2: :   1%|          | 1076/200000 [19:30<19:01:51,  2.90it/s, loss=0.505]stage 2: :   1%|          | 1076/200000 [19:30<19:01:51,  2.90it/s, loss=0.588]<=============================== step 1076  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3510], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike by a riverside with wildflowers blooming nearby\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1076/200000 [19:31<19:01:51,  2.90it/s, loss=0.588]stage 2: :   1%|          | 1080/200000 [19:31<18:45:50,  2.94it/s, loss=0.588]stage 2: :   1%|          | 1080/200000 [19:31<18:45:50,  2.94it/s, loss=0.517]<=============================== step 1080  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.6755], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1080/200000 [19:32<18:45:50,  2.94it/s, loss=0.517]stage 2: :   1%|          | 1084/200000 [19:33<18:31:02,  2.98it/s, loss=0.517]stage 2: :   1%|          | 1084/200000 [19:33<18:31:02,  2.98it/s, loss=0.506]<=============================== step 1084  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0841], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1084/200000 [19:33<18:31:02,  2.98it/s, loss=0.506]stage 2: :   1%|          | 1088/200000 [19:34<18:18:46,  3.02it/s, loss=0.506]stage 2: :   1%|          | 1088/200000 [19:34<18:18:46,  3.02it/s, loss=0.487]<=============================== step 1088  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.3963], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1088/200000 [19:35<18:18:46,  3.02it/s, loss=0.487]stage 2: :   1%|          | 1092/200000 [19:35<18:16:29,  3.02it/s, loss=0.487]stage 2: :   1%|          | 1092/200000 [19:35<18:16:29,  3.02it/s, loss=0.494]<=============================== step 1092  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5831], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1092/200000 [19:36<18:16:29,  3.02it/s, loss=0.494]stage 2: :   1%|          | 1096/200000 [19:37<18:15:54,  3.02it/s, loss=0.494]stage 2: :   1%|          | 1096/200000 [19:37<18:15:54,  3.02it/s, loss=0.479]<=============================== step 1096  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9548], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1096/200000 [19:37<18:15:54,  3.02it/s, loss=0.479]stage 2: :   1%|          | 1100/200000 [19:38<18:15:42,  3.03it/s, loss=0.479]stage 2: :   1%|          | 1100/200000 [19:38<18:15:42,  3.03it/s, loss=0.376]<=============================== step 1100  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6632], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a bus']
stage 2: :   1%|          | 1100/200000 [19:39<18:15:42,  3.03it/s, loss=0.376]stage 2: :   1%|          | 1104/200000 [19:39<18:10:52,  3.04it/s, loss=0.376]stage 2: :   1%|          | 1104/200000 [19:39<18:10:52,  3.04it/s, loss=0.554]<=============================== step 1104  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.4086], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1104/200000 [19:40<18:10:52,  3.04it/s, loss=0.554]stage 2: :   1%|          | 1108/200000 [19:41<18:08:42,  3.04it/s, loss=0.554]stage 2: :   1%|          | 1108/200000 [19:41<18:08:42,  3.04it/s, loss=0.509]<=============================== step 1108  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3142], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1108/200000 [19:41<18:08:42,  3.04it/s, loss=0.509]stage 2: :   1%|          | 1112/200000 [19:42<19:27:34,  2.84it/s, loss=0.509]stage 2: :   1%|          | 1112/200000 [19:42<19:27:34,  2.84it/s, loss=0.644]<=============================== step 1112  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8274], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1112/200000 [19:43<19:27:34,  2.84it/s, loss=0.644]stage 2: :   1%|          | 1116/200000 [19:44<19:06:48,  2.89it/s, loss=0.644]stage 2: :   1%|          | 1116/200000 [19:44<19:06:48,  2.89it/s, loss=0.421]<=============================== step 1116  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0020], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ['a photo of a bnha pickup truck in space with the Milky Way galaxy stretching across the background ', 'a photo of a pickup truck']
stage 2: :   1%|          | 1116/200000 [19:44<19:06:48,  2.89it/s, loss=0.421]stage 2: :   1%|          | 1120/200000 [19:45<18:55:59,  2.92it/s, loss=0.421]stage 2: :   1%|          | 1120/200000 [19:45<18:55:59,  2.92it/s, loss=0.712]<=============================== step 1120  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.6775], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1120/200000 [19:45<18:55:59,  2.92it/s, loss=0.712]stage 2: :   1%|          | 1124/200000 [19:46<18:47:12,  2.94it/s, loss=0.712]stage 2: :   1%|          | 1124/200000 [19:46<18:47:12,  2.94it/s, loss=0.679]<=============================== step 1124  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.2935], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1124/200000 [19:47<18:47:12,  2.94it/s, loss=0.679]stage 2: :   1%|          | 1128/200000 [19:47<18:36:07,  2.97it/s, loss=0.679]stage 2: :   1%|          | 1128/200000 [19:48<18:36:07,  2.97it/s, loss=0.506]<=============================== step 1128  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5501], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1128/200000 [19:48<18:36:07,  2.97it/s, loss=0.506]stage 2: :   1%|          | 1132/200000 [19:49<18:33:07,  2.98it/s, loss=0.506]stage 2: :   1%|          | 1132/200000 [19:49<18:33:07,  2.98it/s, loss=0.698]<=============================== step 1132  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1132/200000 [19:49<18:33:07,  2.98it/s, loss=0.698]stage 2: :   1%|          | 1136/200000 [19:50<18:34:46,  2.97it/s, loss=0.698]stage 2: :   1%|          | 1136/200000 [19:50<18:34:46,  2.97it/s, loss=0.668]<=============================== step 1136  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1765], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1136/200000 [19:51<18:34:46,  2.97it/s, loss=0.668]stage 2: :   1%|          | 1140/200000 [19:52<19:25:12,  2.84it/s, loss=0.668]stage 2: :   1%|          | 1140/200000 [19:52<19:25:12,  2.84it/s, loss=0.45] <=============================== step 1140  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4189], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1140/200000 [19:52<19:25:12,  2.84it/s, loss=0.45]stage 2: :   1%|          | 1144/200000 [19:53<18:42:03,  2.95it/s, loss=0.45]stage 2: :   1%|          | 1144/200000 [19:53<18:42:03,  2.95it/s, loss=0.625]<=============================== step 1144  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1765], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1144/200000 [19:54<18:42:03,  2.95it/s, loss=0.625]stage 2: :   1%|          | 1148/200000 [19:54<18:32:54,  2.98it/s, loss=0.625]stage 2: :   1%|          | 1148/200000 [19:54<18:32:54,  2.98it/s, loss=0.388]<=============================== step 1148  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.6549], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1148/200000 [19:55<18:32:54,  2.98it/s, loss=0.388]stage 2: :   1%|          | 1152/200000 [19:56<18:25:53,  3.00it/s, loss=0.388]stage 2: :   1%|          | 1152/200000 [19:56<18:25:53,  3.00it/s, loss=0.497]<=============================== step 1152  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7945], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1152/200000 [19:56<18:25:53,  3.00it/s, loss=0.497]stage 2: :   1%|          | 1156/200000 [19:57<18:16:01,  3.02it/s, loss=0.497]stage 2: :   1%|          | 1156/200000 [19:57<18:16:01,  3.02it/s, loss=0.519]<=============================== step 1156  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8029], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1156/200000 [19:58<18:16:01,  3.02it/s, loss=0.519]stage 2: :   1%|          | 1160/200000 [19:58<18:12:37,  3.03it/s, loss=0.519]stage 2: :   1%|          | 1160/200000 [19:58<18:12:37,  3.03it/s, loss=0.367]<=============================== step 1160  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2793], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1160/200000 [19:59<18:12:37,  3.03it/s, loss=0.367]stage 2: :   1%|          | 1164/200000 [20:00<18:52:09,  2.93it/s, loss=0.367]stage 2: :   1%|          | 1164/200000 [20:00<18:52:09,  2.93it/s, loss=0.589]<=============================== step 1164  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.2915], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1164/200000 [20:00<18:52:09,  2.93it/s, loss=0.589]stage 2: :   1%|          | 1168/200000 [20:01<18:30:51,  2.98it/s, loss=0.589]stage 2: :   1%|          | 1168/200000 [20:01<18:30:51,  2.98it/s, loss=0.576]<=============================== step 1168  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9897], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1168/200000 [20:02<18:30:51,  2.98it/s, loss=0.576]stage 2: :   1%|          | 1172/200000 [20:02<18:14:08,  3.03it/s, loss=0.576]stage 2: :   1%|          | 1172/200000 [20:02<18:14:08,  3.03it/s, loss=0.613]<=============================== step 1172  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5831], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1172/200000 [20:03<18:14:08,  3.03it/s, loss=0.613]stage 2: :   1%|          | 1176/200000 [20:04<18:11:09,  3.04it/s, loss=0.613]stage 2: :   1%|          | 1176/200000 [20:04<18:11:09,  3.04it/s, loss=0.375]<=============================== step 1176  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.9671], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion on a rocky cliff overlooking a vast ocean\n', 'a photo of a lion']
stage 2: :   1%|          | 1176/200000 [20:04<18:11:09,  3.04it/s, loss=0.375]stage 2: :   1%|          | 1180/200000 [20:05<18:18:10,  3.02it/s, loss=0.375]stage 2: :   1%|          | 1180/200000 [20:05<18:18:10,  3.02it/s, loss=0.671]<=============================== step 1180  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.2689], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a jeep']
stage 2: :   1%|          | 1180/200000 [20:06<18:18:10,  3.02it/s, loss=0.671]stage 2: :   1%|          | 1184/200000 [20:06<18:13:19,  3.03it/s, loss=0.671]stage 2: :   1%|          | 1184/200000 [20:06<18:13:19,  3.03it/s, loss=0.484]<=============================== step 1184  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9076], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike by a riverside with wildflowers blooming nearby\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1184/200000 [20:07<18:13:19,  3.03it/s, loss=0.484]stage 2: :   1%|          | 1188/200000 [20:08<18:18:59,  3.02it/s, loss=0.484]stage 2: :   1%|          | 1188/200000 [20:08<18:18:59,  3.02it/s, loss=0.467]<=============================== step 1188  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.3038], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1188/200000 [20:08<18:18:59,  3.02it/s, loss=0.467]stage 2: :   1%|          | 1192/200000 [20:09<18:09:10,  3.04it/s, loss=0.467]stage 2: :   1%|          | 1192/200000 [20:09<18:09:10,  3.04it/s, loss=0.453]<=============================== step 1192  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8294], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1192/200000 [20:09<18:09:10,  3.04it/s, loss=0.453]stage 2: :   1%|          | 1196/200000 [20:10<18:01:20,  3.06it/s, loss=0.453]stage 2: :   1%|          | 1196/200000 [20:10<18:01:20,  3.06it/s, loss=0.66] <=============================== step 1196  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0020], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant on a rocky cliff overlooking a vast ocean\n', 'a photo of a elephant']
stage 2: :   1%|          | 1196/200000 [20:11<18:01:20,  3.06it/s, loss=0.66]stage 2: :   1%|          | 1200/200000 [20:11<18:14:59,  3.03it/s, loss=0.66]stage 2: :   1%|          | 1200/200000 [20:12<18:14:59,  3.03it/s, loss=0.593]<=============================== step 1200  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1519], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1200/200000 [20:12<18:14:59,  3.03it/s, loss=0.593]stage 2: :   1%|          | 1204/200000 [20:13<17:59:34,  3.07it/s, loss=0.593]stage 2: :   1%|          | 1204/200000 [20:13<17:59:34,  3.07it/s, loss=0.667]<=============================== step 1204  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1087], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1204/200000 [20:13<17:59:34,  3.07it/s, loss=0.667]stage 2: :   1%|          | 1208/200000 [20:14<17:58:28,  3.07it/s, loss=0.667]stage 2: :   1%|          | 1208/200000 [20:14<17:58:28,  3.07it/s, loss=0.457]<=============================== step 1208  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8727], device='cuda:0')
subjects: ['bus']
controlnet: [True]
prompts: ['a photo of a bnha bus in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a bus']
stage 2: :   1%|          | 1208/200000 [20:15<17:58:28,  3.07it/s, loss=0.457]stage 2: :   1%|          | 1212/200000 [20:15<18:24:31,  3.00it/s, loss=0.457]stage 2: :   1%|          | 1212/200000 [20:16<18:24:31,  3.00it/s, loss=0.441]<=============================== step 1212  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5029], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1212/200000 [20:16<18:24:31,  3.00it/s, loss=0.441]stage 2: :   1%|          | 1216/200000 [20:17<18:13:20,  3.03it/s, loss=0.441]stage 2: :   1%|          | 1216/200000 [20:17<18:13:20,  3.03it/s, loss=0.531]<=============================== step 1216  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4538], device='cuda:0')
subjects: ['pickup truck']
controlnet: [True]
prompts: ["a photo of a bnha pickup truck at a river's edge with stones scattered around\n", 'a photo of a pickup truck']
stage 2: :   1%|          | 1216/200000 [20:18<18:13:20,  3.03it/s, loss=0.531]stage 2: :   1%|          | 1220/200000 [20:18<18:56:24,  2.92it/s, loss=0.531]stage 2: :   1%|          | 1220/200000 [20:18<18:56:24,  2.92it/s, loss=0.739]<=============================== step 1220  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9425], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1220/200000 [20:19<18:56:24,  2.92it/s, loss=0.739]stage 2: :   1%|          | 1224/200000 [20:20<18:39:54,  2.96it/s, loss=0.739]stage 2: :   1%|          | 1224/200000 [20:20<18:39:54,  2.96it/s, loss=0.485]<=============================== step 1224  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1224/200000 [20:20<18:39:54,  2.96it/s, loss=0.485]stage 2: :   1%|          | 1228/200000 [20:21<18:47:05,  2.94it/s, loss=0.485]stage 2: :   1%|          | 1228/200000 [20:21<18:47:05,  2.94it/s, loss=0.443]<=============================== step 1228  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0246], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a snowy forest, with a gentle snowfall and snow-covered trees\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1228/200000 [20:22<18:47:05,  2.94it/s, loss=0.443]stage 2: :   1%|          | 1232/200000 [20:22<18:35:49,  2.97it/s, loss=0.443]stage 2: :   1%|          | 1232/200000 [20:22<18:35:49,  2.97it/s, loss=0.653]<=============================== step 1232  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.6303], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1232/200000 [20:23<18:35:49,  2.97it/s, loss=0.653]stage 2: :   1%|          | 1236/200000 [20:24<18:31:48,  2.98it/s, loss=0.653]stage 2: :   1%|          | 1236/200000 [20:24<18:31:48,  2.98it/s, loss=0.393]<=============================== step 1236  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2463], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1236/200000 [20:24<18:31:48,  2.98it/s, loss=0.393]stage 2: :   1%|          | 1240/200000 [20:25<18:37:49,  2.96it/s, loss=0.393]stage 2: :   1%|          | 1240/200000 [20:25<18:37:49,  2.96it/s, loss=0.52] <=============================== step 1240  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5954], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1240/200000 [20:26<18:37:49,  2.96it/s, loss=0.52]stage 2: :   1%|          | 1244/200000 [20:26<18:35:37,  2.97it/s, loss=0.52]stage 2: :   1%|          | 1244/200000 [20:26<18:35:37,  2.97it/s, loss=0.602]<=============================== step 1244  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5256], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1244/200000 [20:27<18:35:37,  2.97it/s, loss=0.602]stage 2: :   1%|          | 1248/200000 [20:28<18:17:46,  3.02it/s, loss=0.602]stage 2: :   1%|          | 1248/200000 [20:28<18:17:46,  3.02it/s, loss=0.415]<=============================== step 1248  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2094], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep on a rocky cliff overlooking a vast ocean\n', 'a photo of a jeep']
stage 2: :   1%|          | 1248/200000 [20:28<18:17:46,  3.02it/s, loss=0.415]stage 2: :   1%|          | 1252/200000 [20:29<18:36:45,  2.97it/s, loss=0.415]stage 2: :   1%|          | 1252/200000 [20:29<18:36:45,  2.97it/s, loss=0.611]<=============================== step 1252  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.1190], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1252/200000 [20:30<18:36:45,  2.97it/s, loss=0.611]stage 2: :   1%|          | 1256/200000 [20:30<18:42:31,  2.95it/s, loss=0.611]stage 2: :   1%|          | 1256/200000 [20:30<18:42:31,  2.95it/s, loss=0.466]<=============================== step 1256  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7227], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1256/200000 [20:31<18:42:31,  2.95it/s, loss=0.466]stage 2: :   1%|          | 1260/200000 [20:32<18:38:19,  2.96it/s, loss=0.466]stage 2: :   1%|          | 1260/200000 [20:32<18:38:19,  2.96it/s, loss=0.45] <=============================== step 1260  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.1642], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1260/200000 [20:32<18:38:19,  2.96it/s, loss=0.45]stage 2: :   1%|          | 1264/200000 [20:33<18:31:55,  2.98it/s, loss=0.45]stage 2: :   1%|          | 1264/200000 [20:33<18:31:55,  2.98it/s, loss=0.511]<=============================== step 1264  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3058], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1264/200000 [20:34<18:31:55,  2.98it/s, loss=0.511]stage 2: :   1%|          | 1268/200000 [20:34<18:16:26,  3.02it/s, loss=0.511]stage 2: :   1%|          | 1268/200000 [20:34<18:16:26,  3.02it/s, loss=0.591]<=============================== step 1268  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.7330], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1268/200000 [20:35<18:16:26,  3.02it/s, loss=0.591]stage 2: :   1%|          | 1272/200000 [20:36<18:33:47,  2.97it/s, loss=0.591]stage 2: :   1%|          | 1272/200000 [20:36<18:33:47,  2.97it/s, loss=0.555]<=============================== step 1272  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0143], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1272/200000 [20:36<18:33:47,  2.97it/s, loss=0.555]stage 2: :   1%|          | 1276/200000 [20:37<18:26:09,  2.99it/s, loss=0.555]stage 2: :   1%|          | 1276/200000 [20:37<18:26:09,  2.99it/s, loss=0.415]<=============================== step 1276  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.9095], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1276/200000 [20:38<18:26:09,  2.99it/s, loss=0.415]stage 2: :   1%|          | 1280/200000 [20:38<18:19:31,  3.01it/s, loss=0.415]stage 2: :   1%|          | 1280/200000 [20:38<18:19:31,  3.01it/s, loss=0.528]<=============================== step 1280  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3161], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1280/200000 [20:39<18:19:31,  3.01it/s, loss=0.528]stage 2: :   1%|          | 1284/200000 [20:40<18:10:02,  3.04it/s, loss=0.528]stage 2: :   1%|          | 1284/200000 [20:40<18:10:02,  3.04it/s, loss=0.496]<=============================== step 1284  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.7679], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1284/200000 [20:40<18:10:02,  3.04it/s, loss=0.496]stage 2: :   1%|          | 1288/200000 [20:41<18:21:34,  3.01it/s, loss=0.496]stage 2: :   1%|          | 1288/200000 [20:41<18:21:34,  3.01it/s, loss=0.524]<=============================== step 1288  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9199], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1288/200000 [20:42<18:21:34,  3.01it/s, loss=0.524]stage 2: :   1%|          | 1292/200000 [20:42<18:15:51,  3.02it/s, loss=0.524]stage 2: :   1%|          | 1292/200000 [20:42<18:15:51,  3.02it/s, loss=0.566]<=============================== step 1292  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.4661], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1292/200000 [20:43<18:15:51,  3.02it/s, loss=0.566]stage 2: :   1%|          | 1296/200000 [20:44<18:20:40,  3.01it/s, loss=0.566]stage 2: :   1%|          | 1296/200000 [20:44<18:20:40,  3.01it/s, loss=0.573]<=============================== step 1296  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8643], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1296/200000 [20:44<18:20:40,  3.01it/s, loss=0.573]stage 2: :   1%|          | 1300/200000 [20:45<19:07:29,  2.89it/s, loss=0.573]stage 2: :   1%|          | 1300/200000 [20:45<19:07:29,  2.89it/s, loss=0.454]<=============================== step 1300  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3510], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1300/200000 [20:46<19:07:29,  2.89it/s, loss=0.454]stage 2: :   1%|          | 1304/200000 [20:46<18:39:52,  2.96it/s, loss=0.454]stage 2: :   1%|          | 1304/200000 [20:46<18:39:52,  2.96it/s, loss=0.551]<=============================== step 1304  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1785], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1304/200000 [20:47<18:39:52,  2.96it/s, loss=0.551]stage 2: :   1%|          | 1308/200000 [20:48<18:34:36,  2.97it/s, loss=0.551]stage 2: :   1%|          | 1308/200000 [20:48<18:34:36,  2.97it/s, loss=0.612]<=============================== step 1308  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4887], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a sunflower field under a clear blue sky\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1308/200000 [20:48<18:34:36,  2.97it/s, loss=0.612]stage 2: :   1%|          | 1312/200000 [20:49<18:44:37,  2.94it/s, loss=0.612]stage 2: :   1%|          | 1312/200000 [20:49<18:44:37,  2.94it/s, loss=0.615]<=============================== step 1312  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0595], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a lion']
stage 2: :   1%|          | 1312/200000 [20:50<18:44:37,  2.94it/s, loss=0.615]stage 2: :   1%|          | 1316/200000 [20:51<19:10:04,  2.88it/s, loss=0.615]stage 2: :   1%|          | 1316/200000 [20:51<19:10:04,  2.88it/s, loss=0.608]<=============================== step 1316  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.0821], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1316/200000 [20:51<19:10:04,  2.88it/s, loss=0.608]stage 2: :   1%|          | 1320/200000 [20:52<18:46:34,  2.94it/s, loss=0.608]stage 2: :   1%|          | 1320/200000 [20:52<18:46:34,  2.94it/s, loss=0.528]<=============================== step 1320  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.6057], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1320/200000 [20:52<18:46:34,  2.94it/s, loss=0.528]stage 2: :   1%|          | 1324/200000 [20:53<18:31:44,  2.98it/s, loss=0.528]stage 2: :   1%|          | 1324/200000 [20:53<18:31:44,  2.98it/s, loss=0.4]  <=============================== step 1324  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.2812], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1324/200000 [20:54<18:31:44,  2.98it/s, loss=0.4]stage 2: :   1%|          | 1328/200000 [20:55<18:57:55,  2.91it/s, loss=0.4]stage 2: :   1%|          | 1328/200000 [20:55<18:57:55,  2.91it/s, loss=0.463]<=============================== step 1328  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4538], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1328/200000 [20:55<18:57:55,  2.91it/s, loss=0.463]stage 2: :   1%|          | 1332/200000 [20:56<18:52:27,  2.92it/s, loss=0.463]stage 2: :   1%|          | 1332/200000 [20:56<18:52:27,  2.92it/s, loss=0.521]<=============================== step 1332  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1047], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1332/200000 [20:57<18:52:27,  2.92it/s, loss=0.521]stage 2: :   1%|          | 1336/200000 [20:57<18:36:37,  2.97it/s, loss=0.521]stage 2: :   1%|          | 1336/200000 [20:57<18:36:37,  2.97it/s, loss=0.533]<=============================== step 1336  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0944], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1336/200000 [20:58<18:36:37,  2.97it/s, loss=0.533]stage 2: :   1%|          | 1340/200000 [20:59<18:30:37,  2.98it/s, loss=0.533]stage 2: :   1%|          | 1340/200000 [20:59<18:30:37,  2.98it/s, loss=0.415]<=============================== step 1340  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.2011], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1340/200000 [20:59<18:30:37,  2.98it/s, loss=0.415]stage 2: :   1%|          | 1344/200000 [21:00<18:20:36,  3.01it/s, loss=0.415]stage 2: :   1%|          | 1344/200000 [21:00<18:20:36,  3.01it/s, loss=0.428]<=============================== step 1344  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.5831], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a lion']
stage 2: :   1%|          | 1344/200000 [21:01<18:20:36,  3.01it/s, loss=0.428]stage 2: :   1%|          | 1348/200000 [21:01<18:25:50,  2.99it/s, loss=0.428]stage 2: :   1%|          | 1348/200000 [21:01<18:25:50,  2.99it/s, loss=0.553]<=============================== step 1348  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.7596], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1348/200000 [21:02<18:25:50,  2.99it/s, loss=0.553]stage 2: :   1%|          | 1352/200000 [21:03<18:15:28,  3.02it/s, loss=0.553]stage 2: :   1%|          | 1352/200000 [21:03<18:15:28,  3.02it/s, loss=0.579]<=============================== step 1352  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.1067], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1352/200000 [21:03<18:15:28,  3.02it/s, loss=0.579]stage 2: :   1%|          | 1356/200000 [21:04<18:13:42,  3.03it/s, loss=0.579]stage 2: :   1%|          | 1356/200000 [21:04<18:13:42,  3.03it/s, loss=0.574]<=============================== step 1356  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7473], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1356/200000 [21:05<18:13:42,  3.03it/s, loss=0.574]stage 2: :   1%|          | 1360/200000 [21:05<18:26:41,  2.99it/s, loss=0.574]stage 2: :   1%|          | 1360/200000 [21:05<18:26:41,  2.99it/s, loss=0.372]<=============================== step 1360  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7350], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1360/200000 [21:06<18:26:41,  2.99it/s, loss=0.372]stage 2: :   1%|          | 1364/200000 [21:07<18:23:48,  3.00it/s, loss=0.372]stage 2: :   1%|          | 1364/200000 [21:07<18:23:48,  3.00it/s, loss=0.371]<=============================== step 1364  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3142], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1364/200000 [21:07<18:23:48,  3.00it/s, loss=0.371]stage 2: :   1%|          | 1368/200000 [21:08<18:13:36,  3.03it/s, loss=0.371]stage 2: :   1%|          | 1368/200000 [21:08<18:13:36,  3.03it/s, loss=0.39] <=============================== step 1368  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2443], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1368/200000 [21:09<18:13:36,  3.03it/s, loss=0.39]stage 2: :   1%|          | 1372/200000 [21:09<18:25:20,  2.99it/s, loss=0.39]stage 2: :   1%|          | 1372/200000 [21:09<18:25:20,  2.99it/s, loss=0.435]<=============================== step 1372  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1372/200000 [21:10<18:25:20,  2.99it/s, loss=0.435]stage 2: :   1%|          | 1376/200000 [21:11<18:43:45,  2.95it/s, loss=0.435]stage 2: :   1%|          | 1376/200000 [21:11<18:43:45,  2.95it/s, loss=0.552]<=============================== step 1376  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0737], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1376/200000 [21:11<18:43:45,  2.95it/s, loss=0.552]stage 2: :   1%|          | 1380/200000 [21:12<19:09:19,  2.88it/s, loss=0.552]stage 2: :   1%|          | 1380/200000 [21:12<19:09:19,  2.88it/s, loss=0.407]<=============================== step 1380  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7124], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1380/200000 [21:13<19:09:19,  2.88it/s, loss=0.407]stage 2: :   1%|          | 1384/200000 [21:13<18:39:17,  2.96it/s, loss=0.407]stage 2: :   1%|          | 1384/200000 [21:13<18:39:17,  2.96it/s, loss=0.581]<=============================== step 1384  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.7576], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1384/200000 [21:14<18:39:17,  2.96it/s, loss=0.581]stage 2: :   1%|          | 1388/200000 [21:15<18:29:59,  2.98it/s, loss=0.581]stage 2: :   1%|          | 1388/200000 [21:15<18:29:59,  2.98it/s, loss=0.517]<=============================== step 1388  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.5152], device='cuda:0')
subjects: ['motorbike']
controlnet: [True]
prompts: ['a photo of a bnha motorbike in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a motorbike']
stage 2: :   1%|          | 1388/200000 [21:15<18:29:59,  2.98it/s, loss=0.517]stage 2: :   1%|          | 1392/200000 [21:16<18:45:32,  2.94it/s, loss=0.517]stage 2: :   1%|          | 1392/200000 [21:16<18:45:32,  2.94it/s, loss=0.504]<=============================== step 1392  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.3058], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1392/200000 [21:17<18:45:32,  2.94it/s, loss=0.504]stage 2: :   1%|          | 1396/200000 [21:17<18:26:15,  2.99it/s, loss=0.504]stage 2: :   1%|          | 1396/200000 [21:17<18:26:15,  2.99it/s, loss=0.554]<=============================== step 1396  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.0737], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1396/200000 [21:18<18:26:15,  2.99it/s, loss=0.554]stage 2: :   1%|          | 1400/200000 [21:19<18:30:35,  2.98it/s, loss=0.554]stage 2: :   1%|          | 1400/200000 [21:19<18:30:35,  2.98it/s, loss=0.661]<=============================== step 1400  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.0246], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep by a riverside with wildflowers blooming nearby\n', 'a photo of a jeep']
stage 2: :   1%|          | 1400/200000 [21:19<18:30:35,  2.98it/s, loss=0.661]stage 2: :   1%|          | 1404/200000 [21:20<18:29:51,  2.98it/s, loss=0.661]stage 2: :   1%|          | 1404/200000 [21:20<18:29:51,  2.98it/s, loss=0.536]<=============================== step 1404  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3633], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ['a photo of a bnha lion on a riverbank at sunrise, with mist rising from the water\n', 'a photo of a lion']
stage 2: :   1%|          | 1404/200000 [21:21<18:29:51,  2.98it/s, loss=0.536]stage 2: :   1%|          | 1408/200000 [21:21<18:30:34,  2.98it/s, loss=0.536]stage 2: :   1%|          | 1408/200000 [21:21<18:30:34,  2.98it/s, loss=0.588]<=============================== step 1408  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.0143], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1408/200000 [21:22<18:30:34,  2.98it/s, loss=0.588]stage 2: :   1%|          | 1412/200000 [21:23<18:27:41,  2.99it/s, loss=0.588]stage 2: :   1%|          | 1412/200000 [21:23<18:27:41,  2.99it/s, loss=0.637]<=============================== step 1412  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.4887], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1412/200000 [21:23<18:27:41,  2.99it/s, loss=0.637]stage 2: :   1%|          | 1416/200000 [21:24<18:20:31,  3.01it/s, loss=0.637]stage 2: :   1%|          | 1416/200000 [21:24<18:20:31,  3.01it/s, loss=0.511]<=============================== step 1416  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5010], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   1%|          | 1416/200000 [21:25<18:20:31,  3.01it/s, loss=0.511]stage 2: :   1%|          | 1420/200000 [21:25<18:06:41,  3.05it/s, loss=0.511]stage 2: :   1%|          | 1420/200000 [21:25<18:06:41,  3.05it/s, loss=0.457]<=============================== step 1420  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.9548], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1420/200000 [21:26<18:06:41,  3.05it/s, loss=0.457]stage 2: :   1%|          | 1424/200000 [21:27<18:00:11,  3.06it/s, loss=0.457]stage 2: :   1%|          | 1424/200000 [21:27<18:00:11,  3.06it/s, loss=0.47] <=============================== step 1424  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.0369], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ["a photo of a bnha elephant at a river's edge with stones scattered around\n", 'a photo of a elephant']
stage 2: :   1%|          | 1424/200000 [21:27<18:00:11,  3.06it/s, loss=0.47]stage 2: :   1%|          | 1428/200000 [21:28<18:09:17,  3.04it/s, loss=0.47]stage 2: :   1%|          | 1428/200000 [21:28<18:09:17,  3.04it/s, loss=0.514]<=============================== step 1428  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1428/200000 [21:29<18:09:17,  3.04it/s, loss=0.514]stage 2: :   1%|          | 1432/200000 [21:29<17:59:29,  3.07it/s, loss=0.514]stage 2: :   1%|          | 1432/200000 [21:29<17:59:29,  3.07it/s, loss=0.419]<=============================== step 1432  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.7104], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1432/200000 [21:30<17:59:29,  3.07it/s, loss=0.419]stage 2: :   1%|          | 1436/200000 [21:31<18:01:21,  3.06it/s, loss=0.419]stage 2: :   1%|          | 1436/200000 [21:31<18:01:21,  3.06it/s, loss=0.528]<=============================== step 1436  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8397], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1436/200000 [21:31<18:01:21,  3.06it/s, loss=0.528]stage 2: :   1%|          | 1440/200000 [21:32<18:19:08,  3.01it/s, loss=0.528]stage 2: :   1%|          | 1440/200000 [21:32<18:19:08,  3.01it/s, loss=0.636]<=============================== step 1440  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3284], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1440/200000 [21:32<18:19:08,  3.01it/s, loss=0.636]stage 2: :   1%|          | 1444/200000 [21:33<18:07:49,  3.04it/s, loss=0.636]stage 2: :   1%|          | 1444/200000 [21:33<18:07:49,  3.04it/s, loss=0.529]<=============================== step 1444  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.5379], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1444/200000 [21:34<18:07:49,  3.04it/s, loss=0.529]stage 2: :   1%|          | 1448/200000 [21:34<17:55:05,  3.08it/s, loss=0.529]stage 2: :   1%|          | 1448/200000 [21:34<17:55:05,  3.08it/s, loss=0.367]<=============================== step 1448  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4907], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1448/200000 [21:35<17:55:05,  3.08it/s, loss=0.367]stage 2: :   1%|          | 1452/200000 [21:36<18:12:29,  3.03it/s, loss=0.367]stage 2: :   1%|          | 1452/200000 [21:36<18:12:29,  3.03it/s, loss=0.349]<=============================== step 1452  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5256], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   1%|          | 1452/200000 [21:37<18:12:29,  3.03it/s, loss=0.349]stage 2: :   1%|          | 1456/200000 [21:37<18:44:24,  2.94it/s, loss=0.349]stage 2: :   1%|          | 1456/200000 [21:37<18:44:24,  2.94it/s, loss=0.524]<=============================== step 1456  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.1436], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1456/200000 [21:38<18:44:24,  2.94it/s, loss=0.524]stage 2: :   1%|          | 1460/200000 [21:39<19:28:13,  2.83it/s, loss=0.524]stage 2: :   1%|          | 1460/200000 [21:39<19:28:13,  2.83it/s, loss=0.529]<=============================== step 1460  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([6.2483], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   1%|          | 1460/200000 [21:39<19:28:13,  2.83it/s, loss=0.529]stage 2: :   1%|          | 1464/200000 [21:40<18:57:32,  2.91it/s, loss=0.529]stage 2: :   1%|          | 1464/200000 [21:40<18:57:32,  2.91it/s, loss=0.49] <=============================== step 1464  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7350], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1464/200000 [21:41<18:57:32,  2.91it/s, loss=0.49]stage 2: :   1%|          | 1468/200000 [21:41<18:43:43,  2.94it/s, loss=0.49]stage 2: :   1%|          | 1468/200000 [21:41<18:43:43,  2.94it/s, loss=0.618]<=============================== step 1468  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.5256], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   1%|          | 1468/200000 [21:42<18:43:43,  2.94it/s, loss=0.618]stage 2: :   1%|          | 1472/200000 [21:43<18:27:15,  2.99it/s, loss=0.618]stage 2: :   1%|          | 1472/200000 [21:43<18:27:15,  2.99it/s, loss=0.585]<=============================== step 1472  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.5010], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   1%|          | 1472/200000 [21:43<18:27:15,  2.99it/s, loss=0.585]stage 2: :   1%|          | 1476/200000 [21:44<18:29:57,  2.98it/s, loss=0.585]stage 2: :   1%|          | 1476/200000 [21:44<18:29:57,  2.98it/s, loss=0.376]<=============================== step 1476  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1662], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   1%|          | 1476/200000 [21:45<18:29:57,  2.98it/s, loss=0.376]stage 2: :   1%|          | 1480/200000 [21:45<18:34:21,  2.97it/s, loss=0.376]stage 2: :   1%|          | 1480/200000 [21:45<18:34:21,  2.97it/s, loss=0.394]<=============================== step 1480  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.4105], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1480/200000 [21:46<18:34:21,  2.97it/s, loss=0.394]stage 2: :   1%|          | 1484/200000 [21:47<18:22:47,  3.00it/s, loss=0.394]stage 2: :   1%|          | 1484/200000 [21:47<18:22:47,  3.00it/s, loss=0.357]<=============================== step 1484  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.7350], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   1%|          | 1484/200000 [21:47<18:22:47,  3.00it/s, loss=0.357]stage 2: :   1%|          | 1488/200000 [21:48<18:13:04,  3.03it/s, loss=0.357]stage 2: :   1%|          | 1488/200000 [21:48<18:13:04,  3.03it/s, loss=0.806]<=============================== step 1488  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.7473], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   1%|          | 1488/200000 [21:49<18:13:04,  3.03it/s, loss=0.806]stage 2: :   1%|          | 1492/200000 [21:49<18:09:09,  3.04it/s, loss=0.806]stage 2: :   1%|          | 1492/200000 [21:49<18:09:09,  3.04it/s, loss=0.37] <=============================== step 1492  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1047], device='cuda:0')
subjects: ['jeep']
controlnet: [True]
prompts: ['a photo of a bnha jeep by a riverside with wildflowers blooming nearby\n', 'a photo of a jeep']
stage 2: :   1%|          | 1492/200000 [21:50<18:09:09,  3.04it/s, loss=0.37]stage 2: :   1%|          | 1496/200000 [21:51<18:21:53,  3.00it/s, loss=0.37]stage 2: :   1%|          | 1496/200000 [21:51<18:21:53,  3.00it/s, loss=0.611]<=============================== step 1496  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.8643], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
