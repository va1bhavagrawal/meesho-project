/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
VLOG_STEPS = [100, 50000, 100000, 150000, 200000]
SAVE_STEPS = [500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
wandb: Currently logged in as: vaibhav-agrawal (vaibhav-agrawal-19). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/rishubhp/.netrc
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/rishubhp/vaibhav/meesho-project/training_scripts/wandb/run-20240821_122422-vuqs00hm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run poseonly_subjectinprompt
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vaibhav-agrawal-19/iisc
wandb: üöÄ View run at https://wandb.ai/vaibhav-agrawal-19/iisc/runs/vuqs00hm
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Updating cross attention only!
['CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnDownBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'CrossAttnUpBlock2D', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'Attention', 'Attention', 'GEGLU', 'UNetMidBlock2DCrossAttn', 'Attention', 'Attention', 'GEGLU']
Differences: 0
/home/rishubhp/miniconda3/envs/contwords/lib/python3.9/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
  0%|          | 0/200000 [00:00<?, ?it/s]<=============================== step 0  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9425], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in front of the Eiffel Tower at sunset with a colorful sky\n', 'a photo of a cat']
stage 2: :   0%|          | 0/200000 [00:01<?, ?it/s]stage 2: :   0%|          | 4/200000 [00:02<30:43:08,  1.81it/s]stage 2: :   0%|          | 4/200000 [00:02<30:43:08,  1.81it/s, loss=0.438]<=============================== step 4  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.3840], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 4/200000 [00:02<30:43:08,  1.81it/s, loss=0.438]stage 2: :   0%|          | 8/200000 [00:02<17:03:24,  3.26it/s, loss=0.438]stage 2: :   0%|          | 8/200000 [00:02<17:03:24,  3.26it/s, loss=0.557]<=============================== step 8  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8274], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 8/200000 [00:02<17:03:24,  3.26it/s, loss=0.557]stage 2: :   0%|          | 12/200000 [00:03<12:50:15,  4.33it/s, loss=0.557]stage 2: :   0%|          | 12/200000 [00:03<12:50:15,  4.33it/s, loss=0.535]<=============================== step 12  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 12/200000 [00:03<12:50:15,  4.33it/s, loss=0.535]stage 2: :   0%|          | 16/200000 [00:03<10:43:11,  5.18it/s, loss=0.535]stage 2: :   0%|          | 16/200000 [00:03<10:43:11,  5.18it/s, loss=0.46] <=============================== step 16  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a medieval castle courtyard with ancient stone walls and archways\n', 'a photo of a cat']
stage 2: :   0%|          | 16/200000 [00:03<10:43:11,  5.18it/s, loss=0.46]stage 2: :   0%|          | 20/200000 [00:04<9:31:52,  5.83it/s, loss=0.46] stage 2: :   0%|          | 20/200000 [00:04<9:31:52,  5.83it/s, loss=0.594]<=============================== step 20  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.6283], device='cuda:0')
subjects: ['horse']
controlnet: [False]
prompts: ['a photo of a bnha horse in front of a dark background', 'a photo of a horse']
stage 2: :   0%|          | 20/200000 [00:04<9:31:52,  5.83it/s, loss=0.594]stage 2: :   0%|          | 24/200000 [00:04<8:57:35,  6.20it/s, loss=0.594]stage 2: :   0%|          | 24/200000 [00:04<8:57:35,  6.20it/s, loss=0.315]<=============================== step 24  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.6303], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 24/200000 [00:05<8:57:35,  6.20it/s, loss=0.315]stage 2: :   0%|          | 28/200000 [00:05<8:30:27,  6.53it/s, loss=0.315]stage 2: :   0%|          | 28/200000 [00:05<8:30:27,  6.53it/s, loss=0.479]<=============================== step 28  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3859], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 28/200000 [00:05<8:30:27,  6.53it/s, loss=0.479]stage 2: :   0%|          | 32/200000 [00:06<8:09:30,  6.81it/s, loss=0.479]stage 2: :   0%|          | 32/200000 [00:06<8:09:30,  6.81it/s, loss=0.605]<=============================== step 32  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.1662], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 32/200000 [00:06<8:09:30,  6.81it/s, loss=0.605]stage 2: :   0%|          | 36/200000 [00:06<7:57:42,  6.98it/s, loss=0.605]stage 2: :   0%|          | 36/200000 [00:06<7:57:42,  6.98it/s, loss=0.692]<=============================== step 36  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.9774], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 36/200000 [00:06<7:57:42,  6.98it/s, loss=0.692]stage 2: :   0%|          | 40/200000 [00:07<7:50:42,  7.08it/s, loss=0.692]stage 2: :   0%|          | 40/200000 [00:07<7:50:42,  7.08it/s, loss=0.526]<=============================== step 40  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([5.9690], device='cuda:0')
subjects: ['elephant']
controlnet: [False]
prompts: ['a photo of a bnha elephant in front of a dark background', 'a photo of a elephant']
stage 2: :   0%|          | 40/200000 [00:07<7:50:42,  7.08it/s, loss=0.526]stage 2: :   0%|          | 44/200000 [00:07<7:43:50,  7.18it/s, loss=0.526]stage 2: :   0%|          | 44/200000 [00:07<7:43:50,  7.18it/s, loss=0.466]<=============================== step 44  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.], device='cuda:0')
subjects: ['elephant']
controlnet: [True]
prompts: ['a photo of a bnha elephant on a rocky cliff overlooking a vast ocean\n', 'a photo of a elephant']
stage 2: :   0%|          | 44/200000 [00:07<7:43:50,  7.18it/s, loss=0.466]stage 2: :   0%|          | 48/200000 [00:08<7:39:18,  7.26it/s, loss=0.466]stage 2: :   0%|          | 48/200000 [00:08<7:39:18,  7.26it/s, loss=0.58] <=============================== step 48  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.8727], device='cuda:0')
subjects: ['jeep']
controlnet: [False]
prompts: ['a photo of a bnha jeep in front of a dark background', 'a photo of a jeep']
stage 2: :   0%|          | 48/200000 [00:08<7:39:18,  7.26it/s, loss=0.58]stage 2: :   0%|          | 52/200000 [00:08<7:36:55,  7.29it/s, loss=0.58]stage 2: :   0%|          | 52/200000 [00:08<7:36:55,  7.29it/s, loss=0.476]<=============================== step 52  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.2793], device='cuda:0')
subjects: ['lion']
controlnet: [True]
prompts: ["a photo of a bnha lion at a river's edge with stones scattered around\n", 'a photo of a lion']
stage 2: :   0%|          | 52/200000 [00:08<7:36:55,  7.29it/s, loss=0.476]stage 2: :   0%|          | 56/200000 [00:09<7:34:52,  7.33it/s, loss=0.476]stage 2: :   0%|          | 56/200000 [00:09<7:34:52,  7.33it/s, loss=0.54] <=============================== step 56  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.3510], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 56/200000 [00:09<7:34:52,  7.33it/s, loss=0.54]stage 2: :   0%|          | 60/200000 [00:09<7:32:35,  7.36it/s, loss=0.54]stage 2: :   0%|          | 60/200000 [00:09<7:32:35,  7.36it/s, loss=0.579]<=============================== step 60  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([2.8972], device='cuda:0')
subjects: ['cat']
controlnet: [True]
prompts: ['a photo of a bnha cat in a vast desert with towering sand dunes and a clear blue sky\n', 'a photo of a cat']
stage 2: :   0%|          | 60/200000 [00:09<7:32:35,  7.36it/s, loss=0.579]stage 2: :   0%|          | 64/200000 [00:10<7:34:27,  7.33it/s, loss=0.579]stage 2: :   0%|          | 64/200000 [00:10<7:34:27,  7.33it/s, loss=0.568]<=============================== step 64  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1868], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 64/200000 [00:10<7:34:27,  7.33it/s, loss=0.568]stage 2: :   0%|          | 68/200000 [00:10<7:43:14,  7.19it/s, loss=0.568]stage 2: :   0%|          | 68/200000 [00:10<7:43:14,  7.19it/s, loss=0.623]<=============================== step 68  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.8850], device='cuda:0')
subjects: ['motorbike']
controlnet: [False]
prompts: ['a photo of a bnha motorbike in front of a dark background', 'a photo of a motorbike']
stage 2: :   0%|          | 68/200000 [00:11<7:43:14,  7.19it/s, loss=0.623]stage 2: :   0%|          | 72/200000 [00:11<7:40:17,  7.24it/s, loss=0.623]stage 2: :   0%|          | 72/200000 [00:11<7:40:17,  7.24it/s, loss=0.669]<=============================== step 72  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9567], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 72/200000 [00:11<7:40:17,  7.24it/s, loss=0.669]stage 2: :   0%|          | 76/200000 [00:12<7:42:00,  7.21it/s, loss=0.669]stage 2: :   0%|          | 76/200000 [00:12<7:42:00,  7.21it/s, loss=0.554]<=============================== step 76  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([0.1396], device='cuda:0')
subjects: ['bus']
controlnet: [False]
prompts: ['a photo of a bnha bus in front of a dark background', 'a photo of a bus']
stage 2: :   0%|          | 76/200000 [00:12<7:42:00,  7.21it/s, loss=0.554]stage 2: :   0%|          | 80/200000 [00:12<7:41:18,  7.22it/s, loss=0.554]stage 2: :   0%|          | 80/200000 [00:12<7:41:18,  7.22it/s, loss=0.401]<=============================== step 80  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.9916], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 80/200000 [00:12<7:41:18,  7.22it/s, loss=0.401]stage 2: :   0%|          | 84/200000 [00:13<7:39:49,  7.25it/s, loss=0.401]stage 2: :   0%|          | 84/200000 [00:13<7:39:49,  7.25it/s, loss=0.455]<=============================== step 84  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.4208], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 84/200000 [00:13<7:39:49,  7.25it/s, loss=0.455]stage 2: :   0%|          | 88/200000 [00:13<7:41:30,  7.22it/s, loss=0.455]stage 2: :   0%|          | 88/200000 [00:13<7:41:30,  7.22it/s, loss=0.654]<=============================== step 88  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([4.3982], device='cuda:0')
subjects: ['cat']
controlnet: [False]
prompts: ['a photo of a bnha cat in front of a dark background', 'a photo of a cat']
stage 2: :   0%|          | 88/200000 [00:13<7:41:30,  7.22it/s, loss=0.654]stage 2: :   0%|          | 92/200000 [00:14<7:42:40,  7.20it/s, loss=0.654]stage 2: :   0%|          | 92/200000 [00:14<7:42:40,  7.20it/s, loss=0.443]<=============================== step 92  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([3.8397], device='cuda:0')
subjects: ['lion']
controlnet: [False]
prompts: ['a photo of a bnha lion in front of a dark background', 'a photo of a lion']
stage 2: :   0%|          | 92/200000 [00:14<7:42:40,  7.20it/s, loss=0.443]stage 2: :   0%|          | 96/200000 [00:14<7:46:42,  7.14it/s, loss=0.443]stage 2: :   0%|          | 96/200000 [00:14<7:46:42,  7.14it/s, loss=0.648]<=============================== step 96  ======================================>
prompt_ids: torch.Size([2, 77])
pixel_values: torch.Size([2, 3, 512, 512])
scalers: tensor([1.1170], device='cuda:0')
subjects: ['pickup truck']
controlnet: [False]
prompts: ['a photo of a bnha pickup truck in front of a dark background', 'a photo of a pickup truck']
stage 2: :   0%|          | 96/200000 [00:14<7:46:42,  7.14it/s, loss=0.648]stage 2: :   0%|          | 100/200000 [00:15<7:50:18,  7.08it/s, loss=0.648]azimuth = 0.0
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.05555555555555555
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.1111111111111111
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.16666666666666666
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.2222222222222222
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.2777777777777778
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.3333333333333333
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.3888888888888889
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.4444444444444444
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.5
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.5555555555555556
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.6111111111111112
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.6666666666666666
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.7222222222222222
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.7777777777777778
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.8333333333333334
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.8888888888888888
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
azimuth = 0.9444444444444444
subject_prompt = 'a photo of a bnha pickup truck in front of a dark background'
subject_prompt = 'a photo of a bnha sedan in front of a dark background'
subject_prompt = 'a photo of a bnha horse in front of a dark background'
every thread finished generating the encoder hidden states...
every thread finished preparing their dataloaders...
starting generation...
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/000.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/001.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/001.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/002.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/004.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/005.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/002.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/003.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/003.jpg']
0 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/005.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/006.jpg']
3 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/009.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/010.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/010.jpg']
2 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/008.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/009.jpg']
1 is doing ['../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/006.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_pickup_truck/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_sedan/007.jpg', '../multiobject/__poseonly_subjectinprompt/outputs_100/tmp/bnha_horse/007.jpg']
